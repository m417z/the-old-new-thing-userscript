<html>
<head>
<title>The cost of trying too hard: String searching</title>
<link rel="stylesheet" href="page.css">
</head><body>
<div class="titlediv"><h2>The cost of trying too hard: String searching</h2></div>
<div class="hdrdiv"><table class="hdrtable" cellspacing="0" cellpadding="0">
<tr><td><b>Date:</b></td><td>January 19, 2006 / year-entry #26</td></tr>
<tr><td><b>Tags:</b></td><td>code</td></tr>
<tr><td><b>Orig Link:</b></td><td>https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603</td></tr>

<tr><td><b>Comments:&nbsp;&nbsp;&nbsp;&nbsp;</b></td><td>22</td></tr>
<tr><td valign="top"><b>Summary:</b></td><td valign="top">There are many algorithms for fast string searching, but the running of a string search is inherently O(n), where n is the length of the string being searched: If m is the length of the string being searched for (which I will call the "target string"), then any algorithm that accesses fewer than n/m elements of the string...</td></tr>
</table></div>
<hr/>
<table class="contenttable" cellspacing="0" cellpadding="0"><tr><td><div class="contentdiv">
<!-- CONTENT START -->
<p>There are many algorithms for fast string searching, but the running of a string search is inherently <i>O</i>(<i>n</i>), where <i>n</i>&nbsp;is the length of the string being searched: If <i>m</i>&nbsp;is the length of the string being searched for (which I will call the "target string"), then any algorithm that accesses fewer than <i>n</i>/<i>m</i>&nbsp;elements of the string being searched will have a gap of <i>m</i> unaccessed elements, which is enough room to hide the target string.</p>
<p> More advanced string searching algorithms can take advantage of characteristics of the target string, but in the general case, where the target string is of moderate size and is not pathological, all that the fancy search algorithms give you over the naive search algorithm is a somewhat smaller multiplicative constant. </p>
<p> In the overwhelming majority of cases, then, a naive search algorithm is adequate. As long as you're searching for normal strings and not edge cases like "Find <code>aaaaaaaaaaaaaaab</code> in the string <code>aaaaaaaaaaaaaabaaaaaaaaaaaaaaab</code>". If you have a self-similar target string, the running time of a naive search is O(<i>mn</i>) where <i>m</i>&nbsp;is the length of the target string. The effort in the advanced searching algorithms goes towards diminishing the effect of&nbsp;<i>m</i>, but pay for it by requiring preliminary analysis of the target string. If your searches are for "relatively short" "normal" target strings, then the benefit of this analysis doesn't merit the cost. </p>
<p> That's why nearly all library functions that do string searching use the naive algorithm. The naive algorithm is the correct algorithm over 99% of the time. </p>
<!-- CONTENT END -->
</div></td></tr></table>
<hr/>
<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (22)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment byuser comment-author-maurits even thread-even depth-1" id="comment-338943">
				<div id="div-comment-338943" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Maurits+%5BMSFT%5D' rel='external nofollow' class='url'>Maurits [MSFT]</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-338943">
			January 19, 2006 at 12:02 pm</a>		</div>

		<p>If you&#8217;re going to be searching the SAME long string over and over again, it is VERY much faster to build an index.  (Assuming the string is non-pathological.)</p>
<p>Compare SQL&#8217;s LIKE &#8216;%butter%&#8217; vs. CONTAINS(&#8230;, &#8216;butter&#8217;, &#8230;) on a large data set.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-338963">
				<div id="div-comment-338963" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Michael Bishop</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-338963">
			January 19, 2006 at 1:45 pm</a>		</div>

		<p>In the past, I needed a very fast way of searching a constant string for many substrings. I built a suffix trie from the data. This allows searching in O(m) time. You sacrifice memory, but when you are looking for short substrings in large text the speed difference is amazing.<br /></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-338973">
				<div id="div-comment-338973" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Chris Moorhouse</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-338973">
			January 19, 2006 at 1:49 pm</a>		</div>

		<p>&quot;The naive algorithm is the correct algorithm over 99% of the time.&quot;</p>
<p>99% of projects? 99% of calls to search functions/methods? 99% of calls <em>made</em> to search functions/methods?</p>
<p>Maybe I just take Mr Lippert too seriously. (&quot;250% of what, exactly?&quot;, Sep 1/05) :D</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-339003">
				<div id="div-comment-339003" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.accidentalscientist.com' rel='external nofollow' class='url'>Simon Cooke</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339003">
			January 19, 2006 at 4:10 pm</a>		</div>

		<p>I still like Boyer-Moore because it only touches each byte once. There&#8217;s a certain elegance there that I really appreciate.</p>
<p>Of course, that&#8217;s all irrelevant because ultimately, Raymond&#8217;s spot on &#8211; most of the time there&#8217;s no advantage to using the more complex one.</p>
<p>Although you can make things better by optimizing the search for the first character of the string :)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-339033">
				<div id="div-comment-339033" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Roger Clark</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339033">
			January 19, 2006 at 5:10 pm</a>		</div>

		<p>&quot;trying too hard&quot; really isn&#8217;t the right phrase to be using here.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-339063">
				<div id="div-comment-339063" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.cryptopunk.com' rel='external nofollow' class='url'>Per Vognsen</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339063">
			January 19, 2006 at 7:27 pm</a>		</div>

		<p>Both this and the previous blog posting on splay trees would have been far more accurately titled &quot;The cost of not understanding the implications of your choices&quot;, although this isn&#8217;t as catchy as yours.</p>
<p>The trend so far (if I may extrapolate from two data points) seems to be that you have an axe to grind with people who uncritically copy algorithms from textbooks. Well, yeah, people like that are pretty common, but copying algorithms uncritically is usually not among their chief failings&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor even thread-even depth-1" id="comment-339083">
				<div id="div-comment-339083" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339083">
			January 19, 2006 at 9:36 pm</a>		</div>

		<p>People will occasionally say things like &quot;Why doesn&#8217;t XYZ use ? It&#8217;s clearly superior to the brute-force algorithm you&#8217;re currently using.&quot; These people are trying too hard. In many cases, the fancy algorithm turns out to be worse than the dumb one.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-339103">
				<div id="div-comment-339103" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Norman Diamond</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339103">
			January 19, 2006 at 9:49 pm</a>		</div>

		<p>I think this case is different from splay trees.  If a smarter algorithm is used, is it really slower in the average case, or does it remain equal in the average case while wrapping up the pathological edge cases?</p>
<p>If you&#8217;re writing a library (write once and use many times), and if performance of the average case doesn&#8217;t deteriorate, then you still get medium-sized gains at cheap cost by choosing a better algorithm.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-339113">
				<div id="div-comment-339113" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.cryptopunk.com' rel='external nofollow' class='url'>Per Vognsen</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339113">
			January 19, 2006 at 9:50 pm</a>		</div>

		<blockquote><p>
  People will occasionally say things like &quot;Why<br />
  <br />&gt;doesn&#8217;t XYZ use ? It&#8217;s clearly superior to the<br />
  <br />&gt;brute-force algorithm you&#8217;re currently using.&quot;<br />
  <br />&gt;These people are trying too hard. In many cases,<br />
  <br />&gt;the fancy algorithm turns out to be worse than<br />
  <br />&gt;the dumb one.</p>
<p>Ah, so you mean that they are trying too hard to apply concepts they were taught about in school (or elsewhere), say. Yes, this is definitely a common affliction.</p>
<p>A friend once related to me the story of one of his final projects for a class on networking concepts, which was to build a simple instant messenger service.</p>
<p>The project was to be built in Java, and one of the things they&#8217;d covered in class was RMI (the Java equivalent of .NET Remoting).</p>
<p>My friend had easily worked out a simple line-delimited TCP/IP-based protocol and had already prototyped and tested it via a simple command-line client, but one of the other team members was very unhappy. He kept wanting to know &quot;How does RMI fit into this?!?&quot;. (RMI is the Java equivalent of .NET Remoting.)
</p></blockquote>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor odd alt thread-odd thread-alt depth-1" id="comment-339123">
				<div id="div-comment-339123" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339123">
			January 19, 2006 at 10:30 pm</a>		</div>

		<p>It&#8217;s more than getting all enamored of fancy algorithms. It&#8217;s just recognizing when you&#8217;re overkilling the problem. Using a fancy hash table to keep track of 5 elements, for example.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-dean-harding even thread-even depth-1" id="comment-339133">
				<div id="div-comment-339133" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Dean+Harding' rel='external nofollow' class='url'>Dean Harding</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339133">
			January 20, 2006 at 12:18 am</a>		</div>

		<p>One of the thing about the Hashcode class in .NET is that it&#8217;s just so easy to use. And &quot;everybody&quot; knows that Hashtables aare as fast as you can get.</p>
<p>So it&#8217;s really annoying when you see people using Hashtables to store a dozen or so values, when a SortedList would be even faster due to it&#8217;s *much* lower overhead&#8230;</p>
<p>The problem is that people just don&#8217;t think about the problem enough&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-339173">
				<div id="div-comment-339173" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Bart</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339173">
			January 20, 2006 at 10:49 am</a>		</div>

		<p>Especially annoying is people using a UnsortedList &#8216;because N will be small&#8217; and then using the app where the N doesn&#8217;t stay small enough.<br />
<br />Especially since they have a HashSet class which exposes the exact same methods used with the same contracts and there aren&#8217;t enough instances to worry about the overhead.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-339213">
				<div id="div-comment-339213" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Jonathan Allen</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339213">
			January 20, 2006 at 1:05 pm</a>		</div>

		<p>In regards to using HashTable vs SortedList in .Net, most people have no way to know which to use. It isn&#8217;t like the documentation is real clear on when to use each, nor does anyone really have to time to performance test non-critical code.</p>
<p>Really all they need to do is add a couple of &quot;when should I use this&quot; lines to each class / method, and the rate of correct usage will go way up.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-339223">
				<div id="div-comment-339223" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">AC</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339223">
			January 20, 2006 at 1:15 pm</a>		</div>

		<p>The best example of overkill is the way Windows Update Agent API works. For any Windows computer to scan for updates, it has to download a CAB file which at the moment contains around fifty thousand(!) XML files totaling 50 MB, to decompress them, parse them etc.<br />
<br />Try that on Pentium II or III and dial-up connection. Instead, all the data could have been stored in a few tab separated files and then compressed.</p>
<p>My second favorite overkill example is the way IE stores cache and history data. It was so complicated that IE was for years unable to maintain its own cache &#8212; something remained forgotten all the time.<br /></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-339333">
				<div id="div-comment-339333" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ken Showman</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339333">
			January 20, 2006 at 5:07 pm</a>		</div>

		<p>The information about the Windows Update Agent (WUA) API that &quot;AC&quot; mentioned above is very misleading.</p>
<p>The Windows Update Agent (WUA) API is designed to search the local computer&#8217;s cache of update metadata. When WUA searches for updates, it actually uses a highly optimized protocol that only picks up new and changed updates, prunes out entire branches of updates based on OS and other applicability rules, omits languages that are not installed on the local machine, and then caches the results in a client-side database. In the usual case, almost nothing is downloaded when WUA performs a search; virtually all of the time &quot;searching for updates&quot; is actually spent running the various applicability rules, e.g. verifying that all of your previously installed patches are still installed and valid.</p>
<p>In order to support API callers on computers where there is no trusted server (such as a computer with no Internet connection), a feature was added to let the API caller supply the giant CAB mentioned above. This CAB is effectively a replacement for the entire WU server, and it includes all updates in all languages because it cannot be known at CAB-generation time which platform(s) the API caller will care about. The data is formatted in XML because that is the same format used by the &quot;real&quot; client-server protocol. The individual XML files in question are never written to disk, so the fact that there are 50,000 of them (as opposed to one giant XML element that contained everything) is beside the point.</p>
<p>Funny that AC suggests that using a tab-delimited file for the CAB scenario would somehow have been less work for the WUA team. That is definitely not the case.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-339393">
				<div id="div-comment-339393" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://nothings.org/computer/source/sgrep.html' rel='external nofollow' class='url'>Sean Barrett</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339393">
			January 21, 2006 at 12:28 am</a>		</div>

		<p>Simon Cooke incorrectly claims Boyer-Moore touches each byte exactly once. Perhaps he is thinking of KMP; Boyer-Moore is one of the &#8216;skip m&#8217; algorithms but it has worst cases that examine more than n characters total, even for no matches.</p>
<p>Also worth considering about the performance of an m-skipping algorithm is that if m is smaller than the cache-line size, you&#8217;ll still be touching every cache line of the (large) string, so any performance gain may be miniscule if the memory traffic dominates.</p>
<p>I invented a skip-m style algorithm for regular-expression searching 15 years ago, but I never did anything with it beyond publishing it on my website, because as Raymond says, it&#8217;s just not that interesting except for very long search strings.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-339403">
				<div id="div-comment-339403" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.cs.stevens.edu/~dlong/' rel='external nofollow' class='url'>Dustin Long</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339403">
			January 21, 2006 at 4:12 am</a>		</div>

		<p>Given that &quot;the world is moving towards webapps&quot;, it helps to implement the non-naive approach nowadays. Assuming you&#8217;re going to be making some internet accessible application, you should better be ready for some fairly pathological arguments to be coming your way.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-339463">
				<div id="div-comment-339463" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">AC</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339463">
			January 23, 2006 at 4:34 am</a>		</div>

		<p>Ken: &quot;Funny that AC suggests that using a tab-delimited file for the CAB scenario would somehow have been less work for the WUA team. That is definitely not the case.&quot;</p>
<p>It&#8217;s not about WUA team&#8217;s work, it&#8217;s how much each computer has to do to find out the updates it needs. Your arguments are all in the direction &quot;we made it to work nicely with server, and if it doesn&#8217;t have the server, then it was easiest for the team to pack everything as 50000 XML files&quot;. I can imagine that this was the easiest for the team to do, but, sorry, that is still the example of the &quot;overkill&quot; design. Instead of nicely preparing the data on source side, once for all millions of users, it remains in the form that was &quot;easiest&quot;.</p>
<p>I really consider &quot;database to XML files&quot; as one of the most inefficient forms for the export of database tables, and &quot;tables to tab separated files&quot; as one of the most efficient. Why would anybody need the names of the fields more than once per table, during the processing of the table?<br /></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-ericlippert even thread-even depth-1" id="comment-339663">
				<div id="div-comment-339663" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Eric+Lippert' rel='external nofollow' class='url'>Eric Lippert</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-339663">
			January 23, 2006 at 2:00 pm</a>		</div>

		<blockquote><p>
  99% of projects? 99% of calls to search functions/methods? 99% of calls <em>made</em> to search functions/methods? </p>
<p>In this case I would say &quot;all of the above&quot;, and follow up with &quot;99% underestimates by a considerable number of orders of magnitude&quot;.</p>
<p>I made the same proposal &#8212; turn this naive algorithm into something &quot;better&quot; &#8212; when I was a naive intern and needed to make some minor changes to the VB implementation of InStr.</p>
<p>Tim &quot;Father of DOS&quot; Paterson owned that code at the time and he taught me a valuable lesson. In the vast majority of real-world cases, the time taken to blaze through the search string looking for all the occurences of the first letter in the target string is <em>far</em> less than the time it takes to scan the string, build the index, blah blah blah.  It&#8217;s the very definition of premature optimization.</p>
<p>We have thousands upon thousands of lines of real-world Visual Basic code in the compatibility lab and people are usually (a) looking for short strings inside other short strings, and (b) their string operations are gated on database or disk performance anyway, so who cares if the string search takes 200 nanoseconds vs 250?</p>
<p>Really, very few people do searches of the entire human genome using InStr in Visual Basic. </p>
<p>
</p></blockquote>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-341103">
				<div id="div-comment-341103" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">dottedmag</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-341103">
			January 26, 2006 at 10:55 am</a>		</div>

		<p>What the library writers don&#8217;t do generally is the documentation of complexity of the algorithms they use. The only such specification I seen so far was the C++ standard. You have to dig the sources usually.<br /></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-341363">
				<div id="div-comment-341363" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">ShameOnYou</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-341363">
			January 27, 2006 at 10:50 am</a>		</div>

		<p>The implementation details isn&#8217;t documented because the programmers are ashamed of implementing a unoptimized algoritm in a library used by millions.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor odd alt thread-odd thread-alt depth-1" id="comment-341373">
				<div id="div-comment-341373" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20060119-11/?p=32603#comment-341373">
			January 27, 2006 at 11:03 am</a>		</div>

		<p>The algorithm *is* optimized. It&#8217;s optimized for non-self-similar strings.</p>

		
				</div>
		</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>

</body>
</html>
<br/><div class="disclaimer">
*DISCLAIMER: I DO NOT OWN THIS CONTENT. If you are the owner and would like it removed, please
<a target="_blank" href="/contact.htm">contact me</a>.
The content herein is an archived reproduction of entries from
Raymond Chen's "Old New Thing" Blog (most recent link is <a target="_blank" href="https://devblogs.microsoft.com/oldnewthing/">here</a>).
It may have slight formatting modifications for consistency and to improve readability.
<br/><br/>
WHY DID I DUPLICATE THIS CONTENT HERE?
Let me first say this site has never had anything to sell and has never shown ads of any kind. I have nothing monetarily to gain by duplicating content here.
Because I had made my own local copy of this content throughout the years, for ease of using tools like grep, I decided to put it online after I discovered
some of the original content previously and publicly available, had disappeared approximately early to mid 2019.
At the same time, I present the content in an easily accessible theme-agnostic way.
<br/><br/>
The information provided by Raymond's blog is, for all practical purposes, more authoritative on Windows Development than Microsoft's
own MSDN documentation and should be considered supplemental reading to that documentation. The wealth of missing details
provided by this blog that Microsoft could not or did not document about Windows over the years is vital enough, many would agree an online "backup" of these details
is a necessary endeavor. Specifics include:<br/>
<ul>
    <li>
        A "redesign" after 2019 erased thousands of user's comments from previous years. As many have stated, the comments are nearly as important as the postings themselves.
        The archived copies of the postings contained here retain the original comments.
    </li>
    <li>
        The blog has changed domains many times and the urls have otherwise been under constant change since 2003.
        Even when proper redirection has been set up for those links, redirection only works for a limited period of time.
        For example, all of the internal blog links that were valid in early 2019, were broken by 2020 without proper redirection.
    </li>
    <li>
        The blog has been under constant re-design and re-theming since its inception.
        It is downright irritating to deal with a bogged-down site experience as the result of the latest visual themes designed for cell-phone browsers.
        As of this writing, it is cumbersome to navigate titles with only 10 entries per page.
        While it is nice that the official site has a search feature, searching using this index (with all titles on a single page) is much quicker (CTRL-F in most browsers).
    </li>
</ul>
</div><br/>
&lt;-- Back to <a href="index.htm">Old New Thing Archive Index</a>

