<html>
<head>
<title>Non-classical processor behavior: How doing something can be faster than not doing it</title>
<link rel="stylesheet" href="page.css">
</head><body>
<div class="titlediv"><h2>Non-classical processor behavior: How doing something can be faster than not doing it</h2></div>
<div class="hdrdiv"><table class="hdrtable" cellspacing="0" cellpadding="0">
<tr><td><b>Date:</b></td><td>June 13, 2014 / year-entry #146</td></tr>
<tr><td><b>Tags:</b></td><td>code</td></tr>
<tr><td><b>Orig Link:</b></td><td>https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743</td></tr>

<tr><td><b>Comments:&nbsp;&nbsp;&nbsp;&nbsp;</b></td><td>53</td></tr>
<tr><td valign="top"><b>Summary:</b></td><td valign="top">Consider the following program: #include <windows.h> #include <stdlib.h> #include <stdlib.h> #include <stdio.h> int array[10000]; int countthem(int boundary) { int count = 0; for (int i = 0; i < 10000; i++) { if (array[i] < boundary) count++; } return count; } int __cdecl wmain(int, wchar_t **) { for (int i = 0; i < 10000;...</td></tr>
</table></div>
<hr/>
<table class="contenttable" cellspacing="0" cellpadding="0"><tr><td><div class="contentdiv">
<!-- CONTENT START -->
<p>
Consider the following program:
</p>
<pre>
#include &lt;windows.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;

int array[10000];

int countthem(int boundary)
{
 int count = 0;
 for (int i = 0; i &lt; 10000; i++) {
  if (array[i] &lt; boundary) count++;
 }
 return count;
}

int __cdecl <a HREF="http://blogs.msdn.com/b/oldnewthing/archive/2014/01/06/10487119.aspx#10487874">wmain</a>(int, wchar_t **)
{
 for (int i = 0; i &lt; 10000; i++) array[i] = rand() % 10;

 for (int boundary = 0; boundary &lt;= 10; boundary++) {
  LARGE_INTEGER liStart, liEnd;
  QueryPerformanceCounter(&amp;liStart);

  int count = 0;
  for (int iterations = 0; iterations &lt; 100; iterations++) {
   count += countthem(boundary);
  }

  QueryPerformanceCounter(&amp;liEnd);
  printf("count=%7d, time = %I64d\n",
         count, liEnd.QuadPart - liStart.QuadPart);
 }
 return 0;
}
</pre>
<p>
The program generates a lot of random integers in the range 0..9
and then counts how many are less than 0, less than 1, less than 2,
and so on.
It also prints how long the operation took in QPC units.
We don't really care how big a QPC unit is; we're just interested
in the relative values.
(We print the number of items found merely to verify that the result
is close to the expected value of <code>boundary * 100000</code>.)
</p>
<p>
Here are the results:
</p>
<table BORDER=1 BORDERCOLOR=1 CELLPADDING=3 CELLSPACING=0
       STYLE="border-collapse: collapse">
<tr>
<th>boundary</th>
<th>count</th>
<th COLSPAN=2>time</th>
</tr>
<tr>
<td ALIGN=right>0</td>
<td ALIGN=right>0</td>
<td ALIGN=right STYLE="border-right: none">1869</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 18.69pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>1</td>
<td ALIGN=right>100000</td>
<td ALIGN=right STYLE="border-right: none">5482</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 54.82pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>2</td>
<td ALIGN=right>200800</td>
<td ALIGN=right STYLE="border-right: none">8152</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 81.52pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>3</td>
<td ALIGN=right>300200</td>
<td ALIGN=right STYLE="border-right: none">10180</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 101.80pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>4</td>
<td ALIGN=right>403100</td>
<td ALIGN=right STYLE="border-right: none">11982</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 119.82pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>5</td>
<td ALIGN=right>497400</td>
<td ALIGN=right STYLE="border-right: none">12092</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 120.92pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>6</td>
<td ALIGN=right>602900</td>
<td ALIGN=right STYLE="border-right: none">11029</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 110.29pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>7</td>
<td ALIGN=right>700700</td>
<td ALIGN=right STYLE="border-right: none">9235</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 92.35pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>8</td>
<td ALIGN=right>797500</td>
<td ALIGN=right STYLE="border-right: none">7051</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 70.51pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>9</td>
<td ALIGN=right>902500</td>
<td ALIGN=right STYLE="border-right: none">4537</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 45.37pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>10</td>
<td ALIGN=right>1000000</td>
<td ALIGN=right STYLE="border-right: none">1864</td>
<td STYLE="border-left: none"><span STYLE="background-color: #66F; display: inline-block; width: 18.64pt">&nbsp;</span></td>
</tr>
</table>
<p>
To the untrained eye, this chart is strange.
Here's the na&iuml;ve analysis:
</p>
<p>
When the boundary is zero, there is no incrementing at all,
so the entire running time is just loop overhead.
You can think of this as our control group.
We can subtract 1869 from the running time of every column
to remove the loop overhead costs.
What remains is the cost of running <code>count</code>
increment instructions.
</p>
<p>
The cost of a single increment operation is highly variable.
At low boundary values, it is around 0.03 time units per increment.
But at high boundary values, the cost drops to one tenth that.
</p>
<p>
What's even weirder is that once the count crosses 600,000,
each addition of another 100,000 increment operations makes the code
run <i>faster</i>,
with the extreme case when
the boundary value reaches 10,
where we run
faster than if we hadn't done any incrementing at all!
</p>
<p>
How can the running time of an increment instruction be <i>negative</i>?
</p>
<p>
The explanation for all this is that CPUs are more complicated
than the na&iuml;ve analysis realizes.
We saw earlier that
<a HREF="http://blogs.msdn.com/b/oldnewthing/archive/2004/12/16/317157.aspx">
modern CPUs contain all sorts of hidden variables</a>.
Today's hidden variable is the branch predictor.
</p>
<p>
Executing a single CPU instruction takes multiple steps,
and modern CPUs kick off multiple instructions in parallel,
with each instruction at a different stage of execution,
a technique known as
<a HREF="http://en.wikipedia.org/wiki/Pipeline_(computing)">
pipelining</a>.
</p>
<p>Conditional branch instructions are bad for pipelining.
Think about it:
When a conditional branch instruction enters the pipeline,
the CPU doesn't know whether the condition will be true
when the instruction reaches the end of the pipeline.
Therefore, it doesn't know what instruction to feed into
the pipeline next.
</p>
<p>
Now, it could just sit there and let the pipeline sit idle
until the branch/no-branch decision is made,
at which point it now knows which instruction to feed into
the pipeline next.
But that wastes a lot of pipeline capacity,
because it will take time for those new instructions to
make it all the way through the pipeline and start
doing productive work.
</p>
<p>
To avoid wasting time, the processor has an internal
<i>branch predictor</i> which remembers the recent
history of which conditional branches were taken and which
were not taken.
The fanciness of the branch predictor varies.
Some processors merely assume that a branch will go the same
way that it did the last time it was countered.
Others keep complicated branch history and try to infer
patterns (such as "the branch is taken every other time").
</p>
<p>
When a conditional branch is encountered,
the branch predictor tells the processor which instructions
to feed into the pipeline.
If the branch prediction turns out to be correct,
then we win!
Execution continues without a pipeline stall.
</p>
<p>
But if the branch prediction turns out to be incorrect,
then we lose!
All of the instructions that were fed into the pipeline
need to be recalled and their effects undone,
and the processor has to go find the correct instructions
and start feeding them into the pipeline.
</p>
<p>
Let's look at our little program again.
When the boundary is 0,
the result of the comparison is always false.
Similarly, when the boundary is 10, the result is always true.
In those cases, the branch predictor can reach 100% accuracy.
</p>
<p>
The worst case is when the boundary is 5.
In that case, half of the time the comparison is true
and half of the time the comparison is false.
And since we have random data,
<a HREF="http://www.amazon.com/gp/search?index=books&keywords=winning+the+lottery&tag=tholneth-20">
fancy historical analysis</a>
doesn't help any.
The predictor is going to be wrong half the time.
</p>
<p>
Here's a tweak to the program:
Change the line
</p>
<pre>
     if (array[i] &lt; boundary) count++;
</pre>
<p>
to
</p>
<pre>
     count += (array[i] &lt; boundary) ? 1 : 0;
</pre>
<p>
This time, the results look like this:
</p>
<table BORDER=1 BORDERCOLOR=1 CELLPADDING=3 CELLSPACING=0
       STYLE="border-collapse: collapse">
<tr>
<th>boundary</th>
<th>count</th>
<th>time</th>
</tr>
<tr>
<td ALIGN=right>0</td>
<td ALIGN=right>0</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2932</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.32pt">&nbsp;</span></td>
</tr>
<tr>
<td ALIGN=right>1</td>
<td ALIGN=right>100000</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2931</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.31pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>2</td>
<td ALIGN=right>200800</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2941</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.41pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>3</td>
<td ALIGN=right>300200</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2931</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.31pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>4</td>
<td ALIGN=right>403100</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2932</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.32pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>5</td>
<td ALIGN=right>497400</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2932</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.32pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>6</td>
<td ALIGN=right>602900</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2932</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.32pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>7</td>
<td ALIGN=right>700700</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2999</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.99pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>8</td>
<td ALIGN=right>797500</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2931</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.31pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>9</td>
<td ALIGN=right>902500</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2932</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.32pt">&nbsp;</span</td>
</tr>
<tr>
<td ALIGN=right>10</td>
<td ALIGN=right>1000000</td>
<td><span STYLE="display: inline-block; width: 5ex; text-align: right">2931</span>
        <span STYLE="background-color: #66F; display: inline-block; width: 29.31pt">&nbsp;</span</td>
</tr>
</table>
<p>
The execution time is now independent of the boundary value.
That's because the optimizer was able to remove the branch from
the ternary expression:
</p>
<pre>
; on entry to the loop, ebx = boundary

    mov edx, offset array ; start at the beginning of the array
$LL3:
    xor ecx, ecx    ; start with zero
    cmp [edx], ebx  ; compare array[i] with boundary
    setl cl         ; if less than boundary, then set al = 1
    add eax, ecx    ; accumulate result in eax

    add edx, 4      ; loop until end of array
    cmp edx, offset array + 40000
    jl $LL3
</pre>
<p>
Since there are no branching decisions in the inner loop
aside from the loop counter,
there is no need for a branch predictor to decide which way
the comparison goes.
The same code executes either way.
</p>
<p>
<b>Exercise</b>:
Why are the counts exactly the same for both runs,
even though the dataset is random?</p>
<!-- CONTENT END -->
</div></td></tr></table>
<hr/>
<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (53)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment even thread-even depth-1" id="comment-1130793">
				<div id="div-comment-1130793" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130793">
			June 13, 2014 at 7:05 am</a>		</div>

		<p>&lt;Insert babble about crypto RNG or lack thereof&gt;</p>
<p>Nah, it&#39;s deliberate to make program runs repeatable.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130803">
				<div id="div-comment-1130803" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Dave</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130803">
			June 13, 2014 at 7:10 am</a>		</div>

		<p>The RNG isn&#39;t initialized in your program, so it just uses a hard-coded default somewhere (in the C runtime?) for it&#39;s seed. &nbsp;This results in the same output from the RNG for each run of the program.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130813">
				<div id="div-comment-1130813" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">VinDuv</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130813">
			June 13, 2014 at 7:13 am</a>		</div>

		<p>The dataset stays the same between runs, because the rand seed is not initialized (srand is not called), thus it has the same (default) value at each run.</p>
<p>Couldn’t the optimizer change the “if (&#8230;) x++;” into “x += &#8230;” automatically ?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130823">
				<div id="div-comment-1130823" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Henke37</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130823">
			June 13, 2014 at 7:16 am</a>		</div>

		<p>VinDuv, the optimizer could do that if x is not volatile and it can deal with all side effects of the condition.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130833">
				<div id="div-comment-1130833" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Gabe</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130833">
			June 13, 2014 at 7:23 am</a>		</div>

		<p>What I find impressive is that it takes 1869 units to count 0 items and 1864 units to count 1000000 items. In other words, it took -4 time units to execute count++ 1000000 times!</p>
<p>Of course it&#39;s not that hard to explain, but I&#39;ll avoid giving the answer in case you&#39;re discussing it in the next episode of &quot;How doing something can be faster than not doing it&quot;.</p>
<div class="post">[<em>I already pointed out that the running time of the increment instruction is negative in case 10. -Raymond</em>]</div>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130843">
				<div id="div-comment-1130843" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joker_vD</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130843">
			June 13, 2014 at 7:23 am</a>		</div>

		<p>How does context switches affect results of QPC? It&#39;s not like whole wmain execution will fit into one quantum, so&#8230; do we actually measure the CPU time spent on wmain? Or the wall time?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130853">
				<div id="div-comment-1130853" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Antonio &amp;#39;Grijan&amp;#39;</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130853">
			June 13, 2014 at 7:48 am</a>		</div>

		<p>The counts are the same in both runs because the dataset isn&#39;t actually random. Calling the rand() function without setup will give you the same sequence of numbers every run, because it&#39;s based in a fixed seed (which, by the way, can be interesting for debugging and testing, because it reduces variance and produces predictable results). To get a truly pseudo-random sequence you must set a different seed every run by calling srand() with some kind of variable argument (such as the current time) at program startup.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130873">
				<div id="div-comment-1130873" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Mordachai</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130873">
			June 13, 2014 at 8:05 am</a>		</div>

		<p>Excellent article! &nbsp;It&#39;s obvious in hind-sight, and I realized immediately it had to be an effect of the branch-predictor, but having the explanation removed the clouds &amp; cobwebs. &nbsp;So, thanks!</p>
<p>Also &#8211; surprised at how much better the code is overall with the ternary instead of the branch. &nbsp;I&#39;ll have to think about using such algorithms more often, if this pattern reappears in my code (as it definitely does sometimes).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130883">
				<div id="div-comment-1130883" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Engywuck</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130883">
			June 13, 2014 at 8:16 am</a>		</div>

		<p>Without reading your explanation I&#39;d at first thought that the compiler was intelligent enough to notice that &quot;all between 0 and x&quot; is the same as &quot;all minus all those between x+1 and 9 (always including the boundaries)&quot; and therefore having the mirrored result. After reading your explanation I slapped my head because it should&#39;ve been obvious&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130893">
				<div id="div-comment-1130893" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">bcs</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130893">
			June 13, 2014 at 8:25 am</a>		</div>

		<p>Any compiler worth it&#39;s bytes will optimize the first version into the branch-less version.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130903">
				<div id="div-comment-1130903" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Adam Rosenfield</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130903">
			June 13, 2014 at 8:43 am</a>		</div>

		<p>@bcs: Agreed. &nbsp;With optimizations turned on, any decent compiler will treat the two code snippets identically. &nbsp;I tested with Clang and got these results for the generated assembly:</p>
<p>At -O0 (no optimization), Clang generates a branch for the if/then version and a branchless cmovl instruction (conditional move if less) instruction for the ternary operator version.</p>
<p>At -O1, it generates branchless bit twiddling code (cmpl, setl, movzbl, addl) for both versions of the source code.</p>
<p>At -O2 and -O3, it generates a branchless version using vectorized SSE instructions.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130913">
				<div id="div-comment-1130913" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Jeffrey Bosboom</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130913">
			June 13, 2014 at 8:55 am</a>		</div>

		<p>There&#39;s an excellent diagnosis of the same effects in this Stack Overflow answer <a rel="nofollow" target="_new" href="https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-an-unsorted-array/11227902#11227902">stackoverflow.com/&#8230;/11227902</a> , this time having to do with presorting the data increasing the branch predictor&#39;s accuracy.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130943">
				<div id="div-comment-1130943" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Raphael</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130943">
			June 13, 2014 at 10:07 am</a>		</div>

		<p>Notice how the second, branch-less version is more efficient&#8230; 8 times out of 10.</p>
<p>If the developer know with a high enough degree of certainty that the branch will be taken either almost always or almost never, the version with a branch is actually a better bet.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-matteo odd alt thread-odd thread-alt depth-1" id="comment-1130953">
				<div id="div-comment-1130953" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Matteo+Italia' rel='external nofollow' class='url'>Matteo Italia</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130953">
			June 13, 2014 at 10:51 am</a>		</div>

		<p>About the non initialized RNG, the C standard substantially says that there&#39;s always an &quot;implicit&quot; srand(1) before the start of the program. </p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130963">
				<div id="div-comment-1130963" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Evan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130963">
			June 13, 2014 at 11:30 am</a>		</div>

		<p>Count me among the people who are surprised by the optimizer not transforming it into the branchless version (assuming optimization was enabled). Even many years ago I noticed that</p>
<p> &nbsp; if (y == 0)</p>
<p> &nbsp; &nbsp; &nbsp;x = 10;</p>
<p> &nbsp; else</p>
<p> &nbsp; &nbsp; &nbsp;x = 30;</p>
<p>is compiled into a branchless version by MSVC &amp; other compilers.</p>
<p>The compiled code varied a bit by compiler of course, but it was in the spirit of</p>
<p> &nbsp; cmp eax, 0 &nbsp;; assume y is in eax; x is in ebx</p>
<p> &nbsp; seteq bl &nbsp; &nbsp;; bl &nbsp;== (y == 0) ? &nbsp;1 : 0</p>
<p> &nbsp; sub ebx, 1 &nbsp;; ebx == (y == 0) ? &nbsp;0 : -1 (0xFF..F)</p>
<p> &nbsp; and ebx, 20 ; ebx == (y == 0) ? &nbsp;0 : 20</p>
<p> &nbsp; add ebx, 10 ; ebx == (y == 0) ? 10 : 30</p>
<p>GCC now uses a cmov instead.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130863">
				<div id="div-comment-1130863" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Antonio &#039;Grijan&#039;</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130863">
			June 13, 2014 at 7:56 am</a>		</div>

		<p>@Gabe: actually, both cases are running almost the same code. In a perfect world, they should give approximately the same units, yes. But we don&#39;t live in a perfect world (yet!), and profiling results are semi-random in nature. For example, even if the system does not count time spent in other threads, they can dirt the processor cache or page out some of our process&#39; memory &#8211; and cache or paging faults in out thread *will* affect profiling, even when the cause lies outside.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130973">
				<div id="div-comment-1130973" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130973">
			June 13, 2014 at 3:07 pm</a>		</div>

		<p>Hmm I don&#39;t know what setqu instruction is and a Google search for &quot;x86 seteq&quot; yielded no good hits. Care to enlighten us?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1130983">
				<div id="div-comment-1130983" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Adam Rosenfield</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130983">
			June 13, 2014 at 3:14 pm</a>		</div>

		<p>@Joshua: I suspect that Evan meant to write &quot;sete&quot; instead of &quot;seteq&quot;. &nbsp;&quot;sete&quot; is one of the class of setcc (set on condition code) instructions (<a rel="nofollow" target="_new" href="http://pdos.csail.mit.edu/6.893/2009/readings/i386/SETcc.htm">pdos.csail.mit.edu/&#8230;/SETcc.htm</a>) which sets the destination to a constant 0 or 1 depending on the values in the (e)flags register from the most recent comparison or arithmetic operation. &nbsp;In the case of sete, it sets the destination to 1 if the last comparison resulted in equality.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1130993">
				<div id="div-comment-1130993" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Daniel Neely</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1130993">
			June 13, 2014 at 4:20 pm</a>		</div>

		<p>Does MSVC&#39;s optimizer fail to figure out it could fix v1 to work like v2; or did you do a non-optimized build to create an interesting result with an easy to understand micro-bench?</p>
<div class="post">[<em>&quot;Compiler optimizations may have been carefully selected for expository purposes.&quot; -Raymond</em>]</div>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131003">
				<div id="div-comment-1131003" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Sebastien Lorion</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131003">
			June 13, 2014 at 4:59 pm</a>		</div>

		<p>I was curious to see if .NET (4.5, VS 2013) was able to optimize for the second case and the answer is no, both versions have the behavior of the branching version. Here is the code:</p>
<p>using System;</p>
<p>using System.Diagnostics;</p>
<p>namespace ConsoleApplication1</p>
<p>{</p>
<p> &nbsp;class Program</p>
<p> &nbsp;{</p>
<p> &nbsp; &nbsp;static void Main(string[] args)</p>
<p> &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp;var rnd = new Random();</p>
<p> &nbsp; &nbsp; &nbsp;for (int i = 0; i &lt; 10000; i++) </p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;array[i] = rnd.Next(10);</p>
<p> &nbsp; &nbsp; &nbsp;var sw = new Stopwatch();</p>
<p> &nbsp; &nbsp; &nbsp;for (int boundary = 0; boundary &lt;= 10; boundary++)</p>
<p> &nbsp; &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;sw.Restart();</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;int count = 0;</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;for (int iterations = 0; iterations &lt; 100; iterations++)</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;count += countthem1(boundary);</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;sw.Stop();</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;Console.WriteLine(&quot;1- count={0,-7}, time = {1}&quot;, count, sw.ElapsedTicks);</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;sw.Restart();</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;count = 0;</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;for (int iterations = 0; iterations &lt; 100; iterations++)</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;count += countthem2(boundary);</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;}</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;sw.Stop();</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;Console.WriteLine(&quot;2- count={0,-7}, time = {1}&quot;, count, sw.ElapsedTicks);</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;Console.WriteLine(&quot;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8212;&#8211;&quot;);</p>
<p> &nbsp; &nbsp; &nbsp;}</p>
<p> &nbsp; &nbsp; &nbsp;Console.ReadLine();</p>
<p> &nbsp; &nbsp;}</p>
<p> &nbsp; &nbsp;static int[] array = new int[10000];</p>
<p> &nbsp; &nbsp;static int countthem1(int boundary)</p>
<p> &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp;int count = 0;</p>
<p> &nbsp; &nbsp; &nbsp;for (int i = 0; i &lt; 10000; i++)</p>
<p> &nbsp; &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;if (array[i] &lt; boundary) count++;</p>
<p> &nbsp; &nbsp; &nbsp;}</p>
<p> &nbsp; &nbsp; &nbsp;return count;</p>
<p> &nbsp; &nbsp;}</p>
<p> &nbsp; &nbsp;static int countthem2(int boundary)</p>
<p> &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp;int count = 0;</p>
<p> &nbsp; &nbsp; &nbsp;for (int i = 0; i &lt; 10000; i++)</p>
<p> &nbsp; &nbsp; &nbsp;{</p>
<p> &nbsp; &nbsp; &nbsp; &nbsp;count += (array[i] &lt; boundary) ? 1 : 0;</p>
<p> &nbsp; &nbsp; &nbsp;}</p>
<p> &nbsp; &nbsp; &nbsp;return count;</p>
<p> &nbsp; &nbsp;}</p>
<p> &nbsp;}</p>
<p>}</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131013">
				<div id="div-comment-1131013" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Muzer_</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131013">
			June 13, 2014 at 6:06 pm</a>		</div>

		<p>I&#39;ve read enough of this type of article such that as soon as I saw the title, I thought &quot;branch predictor&quot;. Glad I wasn&#39;t wrong ;)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131033">
				<div id="div-comment-1131033" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131033">
			June 13, 2014 at 9:52 pm</a>		</div>

		<p>@Josh: It is standard. It&#39;s usually considered bad form to depend on 1 rather than not 0 but hey.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131053">
				<div id="div-comment-1131053" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Myria</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131053">
			June 14, 2014 at 12:59 am</a>		</div>

		<p>I&#39;m wondering whether x86-32 platforms would benefit from using self-modifying code for resolving import thunks due to this problem. &nbsp;Every call to an imported function is an indirect call, which branch predictors just love so much. &nbsp;This is because import thunks are just a pointer variable that gets filled in with the actual address of the imported function or variable. &nbsp;These pointers have names like __imp__SendMessageW@16.</p>
<p>Calling with __declspec(dllimport) set up correctly looks like this:</p>
<p>call dword ptr [__imp__SendMessageW@16]</p>
<p>Calling without using __declspec(dllimport) being used results in the linker generating a stub to fix the problem, at a performance cost:</p>
<p>call near _SendMessageW@16</p>
<p>&#8230;</p>
<p>_SendMessageW@16:</p>
<p>jmp dword ptr [__imp__SendMessageW@16]</p>
<p>Either way, you end up with an indirect branch.</p>
<p>However, what if we compiled as in the second case, without using __declspec(dllimport), but then at runtime did a series of machine code patches? &nbsp;What if we replaced each of these linker-generated stubs with immediate branches like &quot;jmp near _SendMessageW@16&quot;? &nbsp;x86-32 can do immediate branching to its entire address space. &nbsp;(Unlike x86-64, which has the same range as x86-32 for direct branches; this means that it&#39;s limited to &plusmn;2 GB.)</p>
<p>I don&#39;t have enough data to determine whether this is any faster. &nbsp;You do two branches instead of one (comparing to dllimport), but they&#39;re both predictable because they&#39;re unconditional. &nbsp;A solution in which there were a single call instead of a call plus a jmp is possible, but would require a custom linker, and moreover would guarantee that your executable&#39;s code pages would never be shared among processes.</p>
<div class="post">[<em>I think the loss of code page sharing is the killer blow. Without code page sharing, memory usage would skyrocket. -Raymond</em>]</div>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-amroamroamro odd alt thread-odd thread-alt depth-1" id="comment-1131063">
				<div id="div-comment-1131063" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/amroamroamro' rel='external nofollow' class='url'>amroamroamro</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131063">
			June 14, 2014 at 1:27 am</a>		</div>

		<p>Looking at what looks like a normal distribution in the if/then version, can we say anything about the &quot;fanciness&quot; of the branch predictor on your particular processor? If it&#39;s a sophisticated one, can we come up with a specially crafted code to measure the length of the internal branch-history kept for making inferences?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131023">
				<div id="div-comment-1131023" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Josh</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131023">
			June 13, 2014 at 7:32 pm</a>		</div>

		<p>I&#39;ve been doing this for years, though I don&#39;t even bother with the ternary, I just do:</p>
<p>count += array[i] &lt; boundary;</p>
<p>I *think* that&#39;s portable under the C standard, and I&#39;ve never seen it fail, but I&#39;m willing to be contradicted. I doubt it compiles any differently; the mildly optimized assembly from the example ternary is the direct assembly translation of my ternary free approach.</p>
<p>Short summary of article: Branches suck. Try to avoid them in huge loops if you can get the correct behavior using branchless non-boolean binary operators.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131073">
				<div id="div-comment-1131073" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Klimax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131073">
			June 14, 2014 at 2:35 am</a>		</div>

		<p>@Myria</p>
<p>On modern(since Pentium II?) self-modifying code is considered very bad idea and is severely penalized. (pipelines are flushed for example) also it can&#39;t be used because code pages are marked as read-only + executable. (NX bit, would require explicit change in permissions; almost nobody does it)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-iboyd even thread-even depth-1" id="comment-1131083">
				<div id="div-comment-1131083" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/IanBoyd' rel='external nofollow' class='url'>IanBoyd</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131083">
			June 14, 2014 at 5:53 am</a>		</div>

		<p>Eric Brumer [MSFT] gave an excellent presentation at Going Native 2013 that talks about optimizing for the branch predictor:</p>
<p>September 6, 2013</p>
<p>Compiler Confidential &nbsp;</p>
<p><a rel="nofollow" target="_new" href="http://channel9.msdn.com/Events/GoingNative/2013/Compiler-Confidential">channel9.msdn.com/&#8230;/Compiler-Confidential</a></p>
<p>The amazing part, to me, is that he actually busts out a micro-architecture diagram of a single core of a Haswell CPU, and traces the execution of the assembly. (23m mark)</p>
<p>He has four talks on Channel 9. His talks on automatic vectorization, cache misses, store buffers, hot memory, really taught me a lot. I really like his speaking and presentation style. And he doesn&#39;t cop-out with some hand-waving arguments; he actually explains things all the way down, and backs it all up with numbers.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131093">
				<div id="div-comment-1131093" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Myria</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131093">
			June 14, 2014 at 10:25 am</a>		</div>

		<p>@Klimax: This would occur exactly once, at module load time, not every time an imported function is called. &nbsp;It would be no worse than the code patches that already happen due to relocation fixups, which, by the way, already have to disable write protection on executable pages. &nbsp;(This is why Windows Store applications can still get away with self-modifying code if they want, though Microsoft wouldn&#39;t approve them—relocations require the ability to patch the loaded executable. &nbsp;iOS can block this only because their module loading system is based upon position-independent code rather than code patching.)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131103">
				<div id="div-comment-1131103" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Neil</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131103">
			June 14, 2014 at 12:44 pm</a>		</div>

		<p>Some more information on branch prediction in processors can be found here (pp11-36):</p>
<p><a rel="nofollow" target="_new" href="http://www.agner.org/optimize/microarchitecture.pdf">http://www.agner.org/&#8230;/microarchitecture.pdf</a></p>
<p>It also has a section on register renaming where it mentions that the xor cx, cx only costs a decode cycle, so moving it outside of the loop probably makes no difference.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-jan-ringos odd alt thread-odd thread-alt depth-1" id="comment-1131113">
				<div id="div-comment-1131113" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Jan+Ringo%C5%A1' rel='external nofollow' class='url'>Jan Ringoš</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131113">
			June 14, 2014 at 1:51 pm</a>		</div>

		<p>@IanBoyd</p>
<p>Eric also did an excellent talk at Build 2014 on FMA, AVX and store buffer performance: <a rel="nofollow" target="_new" href="http://channel9.msdn.com/Events/Build/2014/4-587">channel9.msdn.com/&#8230;/4-587</a></p>
<p>I highly recommend it.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131123">
				<div id="div-comment-1131123" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Adam</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131123">
			June 14, 2014 at 2:45 pm</a>		</div>

		<p>You can persuade VS 2012 to vectorize this by tweaking the code. It&#39;s not ideal though because it obfuscates the code significantly, and the subtract could overflow. However the performance gains compared to not vectorizing it are significant.</p>
<p>count -= (array[i] &#8211; boundary) &gt;&gt; 31;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131133">
				<div id="div-comment-1131133" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Thomas</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131133">
			June 14, 2014 at 6:02 pm</a>		</div>

		<p>For me, GCC 4.8.1 on Windows produces the fastest code with -O1. -O1 emits setl/addl/movzbl whereas -O3 uses leal/cmovl/addq. The code with setl is about 110 times faster on my Core i7. (24 QPC vs. 2848 QPC)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131143">
				<div id="div-comment-1131143" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Crescens2k</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131143">
			June 14, 2014 at 11:20 pm</a>		</div>

		<p>@Myria:</p>
<p>Could Window Store applications really get away with code patching? Remember part of the executable is the relocations section.</p>
<p>This gives Windows enough information it needs to detect what areas are not supposed to change, and what areas are supposed to change and by how much. I.e. the relocations are supposed to change by the difference between the original base address and the current address that the executable is loaded in at.</p>
<p>For the whole thing of using machine code to patch the import thunks, I doubt it would make much of a difference. The reasoning for this is special, that is most of the execution will be done either in your executable module or in the library itself. You could probably find cases where the call is in a tight loop and it makes a difference, but in general you are more likely to be CPU bound in a tight loop doing stuff on a memory address, IO bound, or even waiting for user input. This of course is personal opinion, and I could very well be totally wrong.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-jan-ringos odd alt thread-odd thread-alt depth-1" id="comment-1131153">
				<div id="div-comment-1131153" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Jan+Ringo%C5%A1' rel='external nofollow' class='url'>Jan Ringoš</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131153">
			June 15, 2014 at 5:43 am</a>		</div>

		<p>@Thomas</p>
<p>Make sure you use also at least -march=nehalem parameter, or better, set precisely which i7 architecture you have. It very much affects choice of instructions being emitted.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131163">
				<div id="div-comment-1131163" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Evan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131163">
			June 15, 2014 at 11:27 am</a>		</div>

		<p>@Klimax: &quot;On modern(since Pentium II?) self-modifying code is considered very bad idea and is severely penalized. (pipelines are flushed for example) also it can&#39;t be used because code pages are marked as read-only + executable. (NX bit, would require explicit change in permissions; almost nobody does it)&quot;</p>
<p>But almost every program does it (actually pretty close to Myria&#39;s suggestion) on ELF systems. The ELF equivalent to the __imp__foo functions on x86 consist of the following sequence conceptually:</p>
<p> &nbsp;L1: jmp L2</p>
<p> &nbsp;L2: push &lt;index&gt;</p>
<p> &nbsp; &nbsp; &nbsp;jmp resolver</p>
<p>The resolver function uses the index pushed in L2 to determine what function is being called and its address in the shared object, and then patch the jump target at L1 to point there. Future calls to foo still transfer to L1, but then immediately jump to the target function. (That also explains the effective nop at L1; it makes it &quot;easier&quot; to patch.)</p>
<p>That means that if you&#39;re using a shared library on Linux for example, you&#39;re using self-modifying code.</p>
<p>Similar to Myria&#39;s suggestion, this is a one-time cost for each function. (Myria&#39;s was one time at load time.) Subsequent calls are probably faster than Windows-style indirect calls.</p>
<p>JITing runtimes are another case of code where you have to deal with changing page permissions. It&#39;s not a big deal in that application because it&#39;s used to bring performance benefits through having a JIT.</p>
<p>In short, yes, one should think carefully before doing something with self-modifying or dynamically generated code. But it&#39;s also applicable much more than you seem to think.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131173">
				<div id="div-comment-1131173" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Klimax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131173">
			June 15, 2014 at 1:48 pm</a>		</div>

		<p>Wrong. Not a self modifying code. It is more of bunch of jumps with runtime dependency, but it still may explain why PIC is so slow&#8230; Classical self-modifying code replaces whole instructions not a variable. What you are posting is classical regular code. (Just few more indirections)</p>
<p>See Intel Optimization guide section 3.6.9 Mixing code and data</p>
<p>&quot;The aggressive prefetching and pre-decoding of instructions by Intel processors have two related effects:</p>
<p>• Self-modifying code works correctly, according to the Intel architecture processor requirements, but</p>
<p>incurs a significant performance penalty. Avoid self-modifying code if possible.&quot;</p>
<p>So, not a good counterexample. Not what I was talking about. Completely different things&#8230; Next attempt at example?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131183">
				<div id="div-comment-1131183" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Klimax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131183">
			June 15, 2014 at 1:58 pm</a>		</div>

		<p>Hm, section 3.6.9.1:</p>
<p>&quot;3.6.9.1 Self-modifying Code</p>
<p>Self-modifying code (SMC) that ran correctly on Pentium III processors and prior implementations will run</p>
<p>correctly on subsequent implementations. SMC and cross-modifying code (when multiple processors in a</p>
<p>multiprocessor system are writing to a code page) should be avoided when high performance is desired.</p>
<p>Software should avoid writing to a code page in the same 1-KByte subpage that is being executed or</p>
<p>fetching code in the same 2-KByte subpage of that is being written. In addition, sharing a page</p>
<p>containing directly or speculatively executed code with another processor as a data page can trigger an</p>
<p>SMC condition that causes the entire pipeline of the machine and the trace cache to be cleared. This is</p>
<p>due to the self-modifying code condition.</p>
<p>Dynamic code need not cause the SMC condition if the code written fills up a data page before that page</p>
<p>is accessed as code. Dynamically-modified code (for example, from target fix-ups) is likely to suffer from</p>
<p>the SMC condition and should be avoided where possible. Avoid the condition by introducing indirect</p>
<p>branches and using data tables on data pages (not code pages) using register-indirect calls.&quot;</p>
<p>Looks like I was too strict and implementation as you both refer to may satisfy SMC condition.</p>
<p>Sorry, I may have been wrong on labeling code, but I was right about implications&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131193">
				<div id="div-comment-1131193" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Evan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131193">
			June 15, 2014 at 2:35 pm</a>		</div>

		<p>I&#39;m not arguing that the fixup won&#39;t cause a performance hit when it occurs. What I&#39;m saying is that the hit that the fixup code causes is a one-time cost (per function) and, once you incur that cost, the fixup-ed code may run faster than the Windows-style based on indirect jumps.</p>
<p>How much faster? I don&#39;t know. Maybe it doesn&#39;t even run faster, though I&#39;d bet a small amount that it would.) Is it enough to make up for the SMC hit? I don&#39;t know. But it&#39;s totally believable that, on the whole, it is. It&#39;s also believable that it isn&#39;t. Or that it depends on the CPU. All I&#39;m arguing against is the categorical statement &quot;SMC is bad don&#39;t use it.&quot; If the SMC buys you larger wins later in execution, then it&#39;s worthwhile.</p>
<p>(Also, I think this choice of cross-module call implementation strategy is independent of PIC; off the top of my head, either the Windows-style indirect-jump strategy or the Linux-style fixup strategy could be used for both Windows-style non-PIC DLLs and Linux-style PIC SOs.)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131203">
				<div id="div-comment-1131203" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Sebastien Lorion</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131203">
			June 15, 2014 at 2:39 pm</a>		</div>

		<p>@Adam: That&#39;s interesting! Do you have any idea why that version works and not the ones suggested by Raymond or Josh ?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131213">
				<div id="div-comment-1131213" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Thomas</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131213">
			June 15, 2014 at 3:41 pm</a>		</div>

		<p>@Jan Ringoš: I tested both with and without -march=native -mtune=native. Didn&#39;t change the results. </p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131223">
				<div id="div-comment-1131223" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">John Doe</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131223">
			June 15, 2014 at 4:42 pm</a>		</div>

		<p>&gt; count += (array[i] &lt; boundary) ? 1 : 0;</p>
<p>&gt; &#8230; the optimizer was able to remove the branch from the ternary expression</p>
<p>This is cheating. &nbsp;Had it been something other than &quot;1 : 0&quot; or &quot;0 : 1&quot;, the compiler would branch. &nbsp;So, it&#39;s not branching itself you&#39;re avoiding, ? : is a branching operator in general. &nbsp;</p>
<p>The only portable way it wouldn&#39;t (shouldn&#39;t, it still may) branch would be relying on C boolean expressions yielding 0 for false and 1 for true, leaving only the comparison expression.</p>
<p>You&#39;re relying on a compiler optimization. &nbsp;The use of ? : is not a generalizable solution, it&#39;s actually very specific and unnecessary.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-cheong odd alt thread-odd thread-alt depth-1" id="comment-1131233">
				<div id="div-comment-1131233" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/cheong00' rel='external nofollow' class='url'>cheong00</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131233">
			June 15, 2014 at 6:55 pm</a>		</div>

		<p>I think this could affect SQL stored procedures as well.</p>
<p>Recently, I was able to optimize a query using &quot;cursor + IF statements to insert into temp table each line&quot; around a few moderately large tables to version that uses subqueries with a few &quot;CASE WHEN &#8230; ELSE &#8230; END&quot; statements on select clause. The execution time reduced from around 1.5 minutes to 1 &#8211; 2 seconds, even if the execution plan show that my version actually created a large intermediate result set before the filtering in the end.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131243">
				<div id="div-comment-1131243" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Magnus</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131243">
			June 15, 2014 at 7:54 pm</a>		</div>

		<p>I&#39;m surprised that while many people have pointed out that the numbers aren&#39;t random because rand() starts with the same seed every time, no-one has pointed out that using rand() % 10 is bad style because the results aren&#39;t randomly distributed. &nbsp;rand() is defined to return a number between 0 and RAND_MAX, which is usually 32767. &nbsp;So a number from 0 to 7 is returned slightly more frequently than 8 and 9. &nbsp;Yes it&#39;s a toy example but this is worth pointing out whenever you use random numbers in an educational article.</p>
<p>When full speed optimisations are turned on, and you use C++ instead of C, the standard algorithms (std::count_if or std::accumulate) should always create code at least as good as an explicit loop. &nbsp;It would be interesting to see how different compilers perform with this example.</p>
<p>Finally, Josh at 13 Jun 2014 7:32 PM and Joshua at 13 Jun 2014 9:52 PM, I don&#39;t see why Josh&#39;s code is &quot;bad form&quot;. &nbsp;A &#39;bool&#39; (in C++, and in C if it has it) is defined to be either 0 or 1, while a numeric is defined to return true if it is non-zero. &nbsp;In fact there is a common idiom to convert a value into an explicit 1 or 0: { int b = !!x; }. &nbsp;If x is 0, this will return 0. &nbsp;If x is non-zero, it will return 1.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131253">
				<div id="div-comment-1131253" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Csaboka</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131253">
			June 15, 2014 at 11:13 pm</a>		</div>

		<p>John Doe:</p>
<p>&gt; This is cheating. &nbsp;Had it been something other than &quot;1 : 0&quot; or &quot;0 : 1&quot;, the compiler would branch.</p>
<p>Not necessarily. It is possible to compile a branchless evaluation of the ternary operator for any two constants around the colon. For example, this is how I would write assembly code for:</p>
<p>count += (array[i] &lt; boundary) ? 42 : 0;</p>
<p>(using the assembly in the article as a starting point)</p>
<p> &nbsp; &nbsp;mov edx, offset array ; start at the beginning of the array</p>
<p>$LL3:</p>
<p> &nbsp; &nbsp;xor ecx, ecx &nbsp; &nbsp;; start with zero</p>
<p> &nbsp; &nbsp;cmp [edx], ebx &nbsp;; compare array[i] with boundary</p>
<p> &nbsp; &nbsp;setnl cl &nbsp; &nbsp; &nbsp; &nbsp;; if less than boundary, then set ecx = 0, otherwise ecx=1</p>
<p> &nbsp; &nbsp;dec ecx &nbsp; &nbsp; &nbsp; &nbsp; ; if less than boundary, then ecx = -1, otherwise ecx=0</p>
<p> &nbsp; &nbsp;or ecx, 42 &nbsp; &nbsp; &nbsp;; if less than boundary, then ecx = 42, otherwise ecx=0</p>
<p> &nbsp; &nbsp;add eax, ecx &nbsp; &nbsp;; accumulate result in eax</p>
<p> &nbsp; &nbsp;add edx, 4 &nbsp; &nbsp; &nbsp;; loop until end of array</p>
<p> &nbsp; &nbsp;cmp edx, offset array + 40000</p>
<p> &nbsp; &nbsp;jl $LL3</p>
<p>If one of the values isn&#39;t zero, you can still use this trick with the difference of the two values, then add the smaller value unconditionally at the end. In other words, the compiler is only forced to branch if at least one expression around the colon has side effects, and as such, they cannot both be evaluated without violating the spec.</p>
<p>Does the VS compiler do the trick I just described? I don&#39;t know, but I certainly hope so. The extra two instructions compared to the &quot;1 : 0&quot; case are still a lot cheaper than a branch.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131263">
				<div id="div-comment-1131263" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Klimax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131263">
			June 16, 2014 at 12:43 am</a>		</div>

		<p>@Evan:</p>
<p>You can&#39;t use it in Windows. Windows automatically mark any page with code as read-only + executable and thus no write into it is permitted. You&#39;d have to have code with sufficient privilege to change permissions. (Loader IIRC does fix ups and then changes protection) And frankly, it is security nightmare.</p>
<p>In &nbsp;short: Use of SMC is not only strongly discouraged, but on Windows by default not possible at all. (Wihtout explicit change by VirtualProtect)</p>
<p>Details on memory protection options: <a rel="nofollow" target="_new" href="http://msdn.microsoft.com/en-us/library/windows/desktop/aa366786(v=vs.85).aspx">msdn.microsoft.com/&#8230;/aa366786(v=vs.85).aspx</a></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131273">
				<div id="div-comment-1131273" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">acq</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131273">
			June 16, 2014 at 3:18 am</a>		</div>

		<p>Csaboka, I&#39;ve checked the output of VC 2010: it used something very much like your trick on 32-bits (but without making the error in the operator, &quot;and&quot; not &quot;or&quot;) and more than that it unrolled the loop a little. On 64-bits it simply used cmovl. Very nice.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131283">
				<div id="div-comment-1131283" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Matt</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131283">
			June 16, 2014 at 3:31 am</a>		</div>

		<p>@Klimax: &quot;You&#39;d have to have code with sufficient privilege to change permissions&quot;.</p>
<p>Every Windows process implicitly has PROCESS_VM_OPERATION permission on its own process. And loader relocation fixups are done in usermode (you mark the RX pages RW to do the fixup, then mark it back RX after you&#39;re done).</p>
<p>Also, you can have sections in your binary that are RWX. The permissions are decided by the binary, not by Windows.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-mike-dimmick odd alt thread-odd thread-alt depth-1" id="comment-1131293">
				<div id="div-comment-1131293" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Mike+Dimmick' rel='external nofollow' class='url'>Mike Dimmick</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131293">
			June 16, 2014 at 4:43 am</a>		</div>

		<p>@Joker_vD: QueryPerformanceCounter time incorporates any context switches. QPC is implemented using whatever hardware timer is available: the lowest cost timer available (in terms of clock cycles required to obtain it) which will produce consistent results.</p>
<p>Historically it was implemented using the rdtsc instruction, but that gave incorrect results if different CPUs ticked at different rates or had been parked, and the thread migrated between different processors. It is now usually implemented with a separate hardware timer, if rdtsc cannot be relied upon. For details, see <a rel="nofollow" target="_new" href="http://msdn.microsoft.com/en-us/library/windows/desktop/dn553408(v=vs.85).aspx">msdn.microsoft.com/&#8230;/dn553408(v=vs.85).aspx</a> .</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131303">
				<div id="div-comment-1131303" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Csaboka</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131303">
			June 16, 2014 at 5:20 am</a>		</div>

		<p>acq:</p>
<p>&gt; but without making the error in the operator, &quot;and&quot; not &quot;or&quot;</p>
<p>D&#39;oh! You are absolutely correct. Looks like my assembly skills are rusty after years of Java work&#8230;</p>
<p>&gt; On 64-bits it simply used cmovl.</p>
<p>Yeah, CMOVcc is nice, but AFAIK it wasn&#39;t guaranteed to be present for quite a while on x86 CPUs, so people tried not to depend on them.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1131313">
				<div id="div-comment-1131313" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">smf</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131313">
			June 16, 2014 at 6:04 am</a>		</div>

		<p>@Myria</p>
<p>&quot;which, by the way, already have to disable write protection on executable pages. &nbsp;(This is why Windows Store applications can still get away with self-modifying code if they want, though Microsoft wouldn&#39;t approve them—relocations require the ability to patch the loaded executable. &nbsp;iOS can block this only because their module loading system is based upon position-independent code rather than code patching.)&quot;</p>
<p>It&#39;s nothing to do with relocations. On all operating systems with write protected code the image is loaded then it&#39;s relocated and finally it&#39;s write protected. Windows Store applications use a JIT compiler, which has to allocate ram, write the program to it and then execute it all the time. It&#39;s theoretically possible for pages to me marked as write protected after they are compiled, but I don&#39;t know if Microsoft do this as it would have an overhead (if the function you compiled doesn&#39;t exactly fill a page then you&#39;re wasting ram).</p>
<p>iOS blocks it because they want every piece of code that is executed to be available to them when the application is submitted (an interpreter or script is also not allowed on iOS but they can&#39;t stop that).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131323">
				<div id="div-comment-1131323" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Evan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131323">
			June 16, 2014 at 6:55 am</a>		</div>

		<p>@John Doe: &quot;This is cheating. &nbsp;Had it been something other than &quot;1 : 0&quot; or &quot;0 : 1&quot;, the compiler would branch. &nbsp;So, it&#39;s not branching itself you&#39;re avoiding, ? : is a branching operator in general. &quot;</p>
<p>No, not true. I even gave an example upthread about the compiler optimizing &quot;if (&#8230;) x=10; else x=20;&quot; into a branchless version, and compilers now generate code that&#39;s even better than when I first saw that. Now, if you stick a function call into one of the branches it won&#39;t be able to do anything*, but there is a wide range of values you could put in the branches. Perhaps any constant. Perhaps anything that doesn&#39;t require actual additional computation. Perhaps even things that *do* require additional computation if the compiler feels it would be more beneficial to compute it unconditionally and ignore the result if the condition is false.</p>
<p>Obviously you won&#39;t avoid branches in many cases, but you&#39;ll avoid branches in more than you think.</p>
<p>(* On x86: some other architectures, e.g. ARM, support predicating lots of instructions. ARM supports predicating calls. It would be totally possible (and believable it would be beneficial!) to compile &quot;if (x==0) foo(); else bar();&quot; to branchless object code (that would be &quot;sub r0, 0; bleq foo; blne bar&quot; if x is in r0), though at least the version of GCC I tried did not actually do so.)</p>
<div class="post">[<em>What if foo returns with Z clear? -Raymond</em>]</div>
<p>@Klimax: &quot;You can&#39;t use it in Windows. Windows automatically mark any page with code as read-only + executable and thus no write into it is permitted. You&#39;d have to have code with sufficient privilege to change permissions. (Loader IIRC does fix ups and then changes protection)&quot;</p>
<p>Here&#39;s my summary of that post: &quot;You can&#39;t do it. Here&#39;s how you do it.&quot;</p>
<p>Remember: mucking about with page permissions to support SMC or other dynamically-generated code isn&#39;t rare. Every .NET program will do it. Every Java program will do it. Every program in any of the other several JITed languages will do it. *Every* program that loads DLLs is at least prepared to do it in case there is an address space conflict and the loader has to rebase the DLL. On many *nix systems, basically *every* program does it at function-call time in a fixup.</p>
<p>Changing page protections isn&#39;t particularly rare, or an edge case. It&#39;s pretty common.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-jonathan-timssungard-com odd alt thread-odd thread-alt depth-1" id="comment-1131433">
				<div id="div-comment-1131433" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/carbon+twelve' rel='external nofollow' class='url'>carbon twelve</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131433">
			June 17, 2014 at 6:19 am</a>		</div>

		<p>@Sebastien Lorion:</p>
<p>The way .NET works means that you can&#39;t be rid of branching by using this transformation.</p>
<p>In C++, the array is static and of fixed size from compile-time and throughout the app&#39;s entire execution; whereas the C# array can be swapped out for another array of different size at any point, for example &#8212; on top of that, unlike in C++, the behaviour of going beyond the range of the array is defined, so whatever you do you end up with a few jumps to verify that you&#39;re within the array bounds when you&#39;re using it.</p>
<p>I think that .NET Native makes some promises to make inroads into this problem with better static analysis.</p>
<p>Also, I note that when I run your code on my machine with the x64 JIT, the &quot;branchless&quot; expression is implemented with a branch anyway &#8212; which now that I read your comment again is exactly what you found so sorry for being redundant.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1131523">
				<div id="div-comment-1131523" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">John Doe</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20140613-00/?p=743#comment-1131523">
			June 17, 2014 at 9:50 am</a>		</div>

		<p>@Evan, point taken.</p>
<p>On ARM, a mispredicted or not predicted branch, be it a conditional call or whatever, will still flush the pipeline, there&#39;s no silver bullet here.</p>

		
				</div>
		</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>

</body>
</html>
<br/><div class="disclaimer">
*DISCLAIMER: I DO NOT OWN THIS CONTENT. If you are the owner and would like it removed, please
<a target="_blank" href="/contact.htm">contact me</a>.
The content herein is an archived reproduction of entries from
Raymond Chen's "Old New Thing" Blog (most recent link is <a target="_blank" href="https://devblogs.microsoft.com/oldnewthing/">here</a>).
It may have slight formatting modifications for consistency and to improve readability.
<br/><br/>
WHY DID I DUPLICATE THIS CONTENT HERE?
Let me first say this site has never had anything to sell and has never shown ads of any kind. I have nothing monetarily to gain by duplicating content here.
Because I had made my own local copy of this content throughout the years, for ease of using tools like grep, I decided to put it online after I discovered
some of the original content previously and publicly available, had disappeared approximately early to mid 2019.
At the same time, I present the content in an easily accessible theme-agnostic way.
<br/><br/>
The information provided by Raymond's blog is, for all practical purposes, more authoritative on Windows Development than Microsoft's
own MSDN documentation and should be considered supplemental reading to that documentation. The wealth of missing details
provided by this blog that Microsoft could not or did not document about Windows over the years is vital enough, many would agree an online "backup" of these details
is a necessary endeavor. Specifics include:<br/>
<ul>
    <li>
        A "redesign" after 2019 erased thousands of user's comments from previous years. As many have stated, the comments are nearly as important as the postings themselves.
        The archived copies of the postings contained here retain the original comments.
    </li>
    <li>
        The blog has changed domains many times and the urls have otherwise been under constant change since 2003.
        Even when proper redirection has been set up for those links, redirection only works for a limited period of time.
        For example, all of the internal blog links that were valid in early 2019, were broken by 2020 without proper redirection.
    </li>
    <li>
        The blog has been under constant re-design and re-theming since its inception.
        It is downright irritating to deal with a bogged-down site experience as the result of the latest visual themes designed for cell-phone browsers.
        As of this writing, it is cumbersome to navigate titles with only 10 entries per page.
        While it is nice that the official site has a search feature, searching using this index (with all titles on a single page) is much quicker (CTRL-F in most browsers).
    </li>
</ul>
</div><br/>
&lt;-- Back to <a href="index.htm">Old New Thing Archive Index</a>

