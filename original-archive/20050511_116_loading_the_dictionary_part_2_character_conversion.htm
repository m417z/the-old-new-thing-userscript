<html>
<head>
<title>Loading the dictionary, part 2:  Character conversion</title>
<link rel="stylesheet" href="page.css">
</head><body>
<div class="titlediv"><h2>Loading the dictionary, part 2:  Character conversion</h2></div>
<div class="hdrdiv"><table class="hdrtable" cellspacing="0" cellpadding="0">
<tr><td><b>Date:</b></td><td>May 11, 2005 / year-entry #117</td></tr>
<tr><td><b>Tags:</b></td><td>code</td></tr>
<tr><td><b>Orig Link:</b></td><td>https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663</td></tr>

<tr><td><b>Comments:&nbsp;&nbsp;&nbsp;&nbsp;</b></td><td>24</td></tr>
<tr><td valign="top"><b>Summary:</b></td><td valign="top">When you want to optimize a program, you first need to know where the time is being spent. There's no point optimizing a function that isn't actually responsible for your poor performance. For example, if a particular function is responsible for 2% of your CPU time, then even if you optimized it down to infinite speed,...</td></tr>
</table></div>
<hr/>
<table class="contenttable" cellspacing="0" cellpadding="0"><tr><td><div class="contentdiv">
<!-- CONTENT START -->
<p>
When you want to optimize a program, you first need to know
where the time is being spent.
There's no point optimizing a function that isn't actually
responsible for your poor performance.
For example, if a particular function is responsible for 2%&nbsp;of
your CPU time, then even if you optimized it down to infinite speed,
your program would speed up at best by only little over&nbsp;2%.
In the comments to yesterday's entry, several people put forth
suggestions as to how the program could be optimized,
in the process quite amply demonstrating this principle.
None of the people who made suggestions actually investigated
the program to see where the glaring bottleneck was.
</p>
<p>
(<a HREF="http://blogs.msdn.com/ricom">Rico Mariani</a> points out that you also
need to take performance in account when doing high level designs,
choosing algorithms and data structures that are suitable for
the level of performance you need.
If profiling reveals that a fundamental design decision
is responsible for a performance bottleneck, you're in big trouble.
You will see this sort of performance-guided design as the program develops.
And you should check out
<a HREF="http://blogs.msdn.com/ricom/archive/2005/05/10/416151.aspx">
Performance Quiz&nbsp;#6</a>
which starts with the very program we're developing here.)
</p>
<p>
Upon profiling our dictionary-loader, I discovered that
80% of the CPU time was spent in <code>getline</code>.
Clearly this is where the focus needs to be.
Everything else is just noise.
</p>
<p>
Digging a little deeper, it turns out that
29% of the CPU time was spent by <code>getline</code> doing
character set conversion in <code>codecvt::do_in</code>.
Some debugging revealed that <code>codecvt::do_in</code>
was being called millions of times, each time converting
just one or two characters.  In fact, for each character
in the file, <code>codecvt::do_in</code> was called once
and sometimes twice!
</p>
<p>
Let's get rid of the piecemeal character set conversion and
instead convert entire lines at a time.
</p>
<pre>
Dictionary::Dictionary()
{
 std::<font COLOR=blue>ifstream</font> src;
 <font COLOR=blue>typedef std::codecvt&lt;wchar_t, char, mbstate_t&gt; widecvt;
 std::locale l(".950");
 const widecvt&amp; cvt = _USE(l, widecvt); // use_facet&lt;widecvt&gt;(l);</font>
 src.open("cedict.b5");
 <font COLOR=blue>string</font> s;
 while (getline(src, s)) {
  if (s.length() &gt; 0 &amp;&amp; s[0] != L'#') {
   <font COLOR=blue>wchar_t* buf = new wchar_t[s.length()];
   mbstate_t state = 0;
   char* nextsrc;
   wchar_t* nextto;
   if (cvt.in(state, s.data(), s.data() + s.length(), nextsrc,
                   buf, buf + s.length(), nextto) == widecvt::ok) {
    wstring line(buf, nextto - buf);</font>
    DictionaryEntry de;
    if (de.Parse(<font COLOR=blue>line</font>)) {
     v.push_back(de);
    }
   <font COLOR=blue>}
   delete[] buf;</font>
  }
 }
}
</pre>
<p>
Instead of using a <code>wifstream</code>,
we just use a non-Unicode <code>ifstream</code>
and convert each line to Unicode manually.
Doing it a line at a time rather than a character at a time,
we hope, will be more efficient.
</p>
<p>
We ask code page 950 for a converter, which we call <code>cvt</code>.
Notice that the Microsoft&nbsp;C++ compiler requires you to use
the strange <code>_USE</code> macro instead of the more traditional
<code>use_facet</code>.
</p>
<p>
For each line that isn't a comment, we convert it to Unicode.
Our lives are complicated by the fact that <code>codecvt::in</code>
requires pointers to elements rather than iterators, which means
that we can't use a <code>wstring</code> or a <code>vector</code>;
we need a plain boring <code>wchar_t[]</code> array.
(Notice that we can cheat on the "from" buffer and use the
<code>string::data()</code> function to get at a read-only
array representation of the string.)
If the conversion succeeds, we convert the array into a proper
string and continue as before.
</p>
<p>
With this tweak, the program now loads the dictionary in 1120ms
(or 1180ms if you include the time it takes to destroy the
dictionary).  That's nearly twice as fast as the previous version.</p>
<p>
You might think that we could avoid redundant allocations
by caching the temporary conversion buffer between lines.
I tried that, and surprisingly, it actually slowed the program
down by 10ms.
Such is
<a HREF="http://blogs.msdn.com/oldnewthing/archive/2004/12/16/317157.aspx">
the counter-intuitive world of optimization</a>.
That's why it's important to identify your bottlenecks via
measurement instead of just guessing at them.</p>
<!-- CONTENT END -->
</div></td></tr></table>
<hr/>
<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (24)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment even thread-even depth-1" id="comment-275343">
				<div id="div-comment-275343" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Jack Mathews</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275343">
			May 11, 2005 at 10:15 am</a>		</div>

		<p>The only real complaint I have about this is the naked pointer usage.</p>
<p>When you new in a naked pointer like that, you kill exception safety.  Let&#8217;s say that widecvt decides to throw an exception (or someone else comes in to fix your code and adds something that can throw an exception in the middle).  Your &quot;new&quot; there just created a memory leak.</p>
<p>If you code in a way where you use vectors or auto_ptr&#8217;s instead of naked pointers, then you&#8217;re always exception safe without leaks.  Exception safe C++ coding has increased our code quality and decreased memory leaks a very, VERY significant amount.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275353">
				<div id="div-comment-275353" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://ramblings.aaronballman.com' rel='external nofollow' class='url'>Aaron Ballman</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275353">
			May 11, 2005 at 10:29 am</a>		</div>

		<p>I&#8217;m curious to know what it is that you used to profile you&#8217;re code?  The only profiler I&#8217;ve ever used is Shark for the Mac &#8212; did you use something similar to that?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275363">
				<div id="div-comment-275363" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Tito</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275363">
			May 11, 2005 at 10:56 am</a>		</div>

		<p>or check out boost&#8217;s scoped_ptr&lt;&gt; rather than auto_ptr&lt;&gt;.  (see <a href="http://www.boost.org" rel="nofollow">http://www.boost.org</a>)</p>
<p>Either way using an raii-style pointer would make the code more readable, since you wouldn&#8217;t need the delete[], which is quite irrelevant to the logic you are demonstrating.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275373">
				<div id="div-comment-275373" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">tomw</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275373">
			May 11, 2005 at 11:00 am</a>		</div>

		<p>I&#8217;m w/ Aaron &#8211; I&#8217;d love to hear a little more about how you did: &quot;Upon profiling our dictionary-loader, I discovered that 80% of the CPU time was spent in getline. Clearly this is where the focus needs to be. Everything else is just noise. </p>
<p>Digging a little deeper, it turns out that 29% of the CPU time was spent by getline doing character set conversion in codecvt::do_in. Some debugging revealed that codecvt::do_in was being called millions of times, each time converting just one or two characters. In fact, for each character in the file, codecvt::do_in was called once and sometimes twice!&quot;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275383">
				<div id="div-comment-275383" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Jerry Pisk</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275383">
			May 11, 2005 at 11:04 am</a>		</div>

		<p>I wonder how can a reusable buffer be slower than calling new and delete every iteration. Especially if you hit your longest line soon in the beginning, or pad it enough so most of your iterations will simply execute a compare (to make sure the buffer is long enough) and go on with their lives. There&#8217;s no way a conditional jump is slower than allocating and freeing memory on the heap.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor odd alt thread-odd thread-alt depth-1" id="comment-275393">
				<div id="div-comment-275393" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275393">
			May 11, 2005 at 11:09 am</a>		</div>

		<p>Excellent point about exception safety. I don&#8217;t normally program with STL or exceptions &#8211; the fact that I&#8217;m using STL at all is a bit of a departure. </p>
<p>If you want more details on using the profiler that comes with VSTS, check out Ian Huff&#8217;s blog <a rel="nofollow" target="_new" href="http://blogs.msdn.com/ianhu/" rel="nofollow">http://blogs.msdn.com/ianhu/</a> and his video on Channel9.</p>
<p>I don&#8217;t know why reusing the buffer made the program slowr but it did. Maybe there are cache effects?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275403">
				<div id="div-comment-275403" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">...</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275403">
			May 11, 2005 at 11:37 am</a>		</div>

		<blockquote><p>
  Our lives are complicated by the fact that codecvt::in requires pointers to elements rather than iterators, which means that we can&#8217;t use a wstring or a vector;</p>
<p>What prevents you from using std::vector&lt;wchar_t&gt;?
</p></blockquote>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor odd alt thread-odd thread-alt depth-1" id="comment-275423">
				<div id="div-comment-275423" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275423">
			May 11, 2005 at 12:02 pm</a>		</div>

		<p>I don&#8217;t see a vector::data() function, nor do I see any guarantee that the elements of a vector are contiguous in memory or that vector::begin() can be treated as a pointer to the first element of the array. Maybe I missed it.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275443">
				<div id="div-comment-275443" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.matbooth.co.uk' rel='external nofollow' class='url'>Mat Booth</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275443">
			May 11, 2005 at 12:13 pm</a>		</div>

		<p>According to the comp.lang.c++ FAQ, the storage for a std::vector&lt;T&gt; is guaranteed to be contiguous. See <a rel="nofollow" target="_new" href="http://www.parashift.com/c++-faq-lite/containers.html#faq-34.3" rel="nofollow">http://www.parashift.com/c++-faq-lite/containers.html#faq-34.3</a></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275453">
				<div id="div-comment-275453" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">indranil banerjee</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275453">
			May 11, 2005 at 12:21 pm</a>		</div>

		<p>The standard was amended to make it clear that vector is required to use contiguous memory</p>
<p><a rel="nofollow" target="_new" href="http://www.open-std.org/jtc1/sc22/wg21/docs/lwg-defects.html" rel="nofollow">http://www.open-std.org/jtc1/sc22/wg21/docs/lwg-defects.html</a></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275473">
				<div id="div-comment-275473" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://blogs.msdn.com/ryanmy/' rel='external nofollow' class='url'>Ryan Myers [MSFT]</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275473">
			May 11, 2005 at 12:36 pm</a>		</div>

		<p>&quot;I don&#8217;t see a vector::data() function, nor do I see any guarantee that the elements of a vector are contiguous in memory or that vector::begin() can be treated as a pointer to the first element of the array. Maybe I missed it.&quot;</p>
<p>vector&lt;T&gt;::begin() should not be treated as a pointer.  &amp;v[0] is, though.</p>
<p>In the original C++ standard (14882-1998) vector was not explicitly required to have contiguous memory, but the complexity requirements on it pretty much ensured it.  In the 2003 revision of the standard, they made that requirement explicit.</p>
<p>I don&#8217;t know of a single STL implementation that has a non-contiguous vector, so it&#8217;s pretty safe.</p>
<p>FYI, do you know if widecvt outputs UCS-2 or UTF-16?  If it&#8217;s UTF-16, then it&#8217;s entirely possible that you could have surrogate pairs (two wchar_ts that represent a single Unicode codepoint).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275493">
				<div id="div-comment-275493" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://blogs.msdn.com/ryanmy/' rel='external nofollow' class='url'>Ryan Myers [MSFT]</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275493">
			May 11, 2005 at 2:21 pm</a>		</div>

		<p>Universalis, most Win32 APIs expect/use UTF-16 when they recieve or return WCHARs.  I have no doubt that there are many apps out there that do not anticipate this.</p>
<p>A problem that&#8217;s even more widespread are apps that expect every Unicode codepoint to be a single grapheme cluster, and thus don&#8217;t support combining characters.  A good example is IE6 &#8212; the Address box handles them correctly, since it is a standard system-wide text edit control.  The windowless controls used for form input in pages, however, do not handle combining characters properly.  (And Firefox is absolutely broken across the board on this.)</p>
<p>Michael Kaplan touched on this a while ago in his blog.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275503">
				<div id="div-comment-275503" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://blogs.msdn.com/ryanmy/' rel='external nofollow' class='url'>Ryan Myers [MSFT]</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275503">
			May 11, 2005 at 2:29 pm</a>		</div>

		<p>To clarify, though, an app that is properly written other than expecting UCS-2 will simply have a broken UI, not a crash.</p>
<p>In UCS-2, the surrogate pair characters are simply two separate characters.  So, if you pass UCS-2 code a surrogate pair, it&#8217;ll expect a string that&#8217;s longer, and render two characters.  This could cause some display bugs, of course, but nothing should be fatal.</p>
<p>This is a good thing, because we didn&#8217;t really support UTF-16 in the UI until WinXP and its ClearType engine; Win2K, for all intents and purposes, acted as though wchar_t/WCHAR was UCS-2.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275523">
				<div id="div-comment-275523" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.codeproject.com/script/profile/whos_who.asp?id=14112' rel='external nofollow' class='url'>Nemanja Trifunovic</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275523">
			May 11, 2005 at 3:08 pm</a>		</div>

		<blockquote><p>
  You might think that we could avoid redundant allocations by caching the temporary conversion buffer between lines. I tried that, and surprisingly, it actually slowed the program down by 10ms. Such is the counter-intuitive world of optimization. </p>
<p>The fact is that CRT is not required to actually return the memory to the OS after a call to free/delete. It can do its own cashing.</p>
<p>As for the exception safety in the sample, the rule of thumb is: whenever you manually call delete out of a destructor, chances are your code is not exception-safe. Using std::vector or (if you believe it is too much overhead &#8211; talk about premature optimization) booost::scoped_array is the key for making the code exception-safe.
</p></blockquote>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275533">
				<div id="div-comment-275533" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Wiill Dean</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275533">
			May 11, 2005 at 3:40 pm</a>		</div>

		<p>&#8216;Slowed down by 10ms&#8217; is almost certainly completely meaningless, because your GetTickCount resolution is very likely to be 10ms.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275553">
				<div id="div-comment-275553" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://luminance.org/' rel='external nofollow' class='url'>Kevin Gadd</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275553">
			May 11, 2005 at 4:35 pm</a>		</div>

		<p>Will Dean: Why on earth would a profiler use GetTickCount? Mine uses QueryPerformanceCounter, which has no such accuracy limitation.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275563">
				<div id="div-comment-275563" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Justin Olbrantz</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275563">
			May 11, 2005 at 8:48 pm</a>		</div>

		<p>I usually profile my functions with the CPU cycle counter on the average of many repetitions, running at realtime priority class. That gives me about +/- 15 cycles accuracy. But that&#8217;s for individual, small functions, not something anywhere near 1120 ms (on my computer, monopolizing the single CPU for even half that long kills the computer).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-universalis odd alt thread-odd thread-alt depth-1" id="comment-275483">
				<div id="div-comment-275483" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Universalis</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275483">
			May 11, 2005 at 1:49 pm</a>		</div>

		<p>That is an excellent point that Ryan Myers has just made. For some reason people (at least, people in a hurry) seem to think that &quot;Unicode&quot; means &quot;16-bit&quot; whereas of course it doesn&#8217;t. I was facing just this problem in a database program that needed to do boil-to-an-indexable-form stuff the whole time, and I ended up making the [deeply] internal character representation 32-bit. I know that the supplementary characters are most of them pretty obscure, but the prospect of a program collapsing or producing unintended behaviour just because &#8211; years down the line &#8211; some non-technical user thinks innocently that &quot;a character is a character&quot; (without appreciating that some of them don&#8217;t fit into 16 bits) is really unacceptable. It&#8217;s a 20-year-old program I&#8217;m working with and it is entirely possible that it will still be in use in 20 years&#8217; time.<br />
<br />For the purpose of the example program whose evolution we&#8217;re watching this may be needless and quixotic, but I think it&#8217;s important for any seriously long-lived program to be able to handle the full Unicode character set even if this means a certain va-et-vient between UTF-8 (best on disk), UTF-16 (which I *think* the Windows API uses, but please correct me) and UCS-4 (which we know can accommodate everything).<br />
<br />If some algorithms are slowed unacceptably by the 32-bit character representation, then later, as an optimisation stage, you might produce 16-bit implementations that are rigorously hidden from the caller &#8211; the internal logic could then be &quot;call 16-bit version and if that fails then call 32-bit version&quot;&#8230; this optimisation being &quot;under the surface&quot; and not available to an inappropriately ingenious caller.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275583">
				<div id="div-comment-275583" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Will Dean</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275583">
			May 12, 2005 at 2:09 am</a>		</div>

		<p>&quot;Why on earth would a profiler use GetTickCount?&quot;: If you look at Raymond&#8217;s code, posted previously, you&#8217;ll see that he&#8217;s using GetTickCount to get the headline &#8216;total time&#8217; figures that he quotes throughout the articles.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275593">
				<div id="div-comment-275593" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.jelovic.com' rel='external nofollow' class='url'>Dejan Jelovic</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275593">
			May 12, 2005 at 6:12 am</a>		</div>

		<p>Raymond, three things:</p>
<p>1. Your code is not exception-safe. Variable buf will leak if an exception is thrown inside the loop.</p>
<p>2. Re the temporary buffer allocation performance: A better solution may be to use a class that contains a default buffer which is then allocated on the stack when, but then allocates the buffer on the heap if the default buffer is not big enough.</p>
<p>3. An unfortunate result of the C++ standard rules concerning vectors is that all emements have to be in a contiguous piece of memory. Thus it&#8217;s valid to obtain pointers to various elements and pass them to codecvt::in. I don&#8217;t know if the same applies to basic_string; maybe Herb Sutter can sched some light.</p>
<p>Dejan</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275603">
				<div id="div-comment-275603" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Will Dean</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275603">
			May 12, 2005 at 6:44 am</a>		</div>

		<p>std::basic_string is not required to be contiguous.  std::vector is.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275613">
				<div id="div-comment-275613" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://www.valhallalegends.com/arta' rel='external nofollow' class='url'>Arta</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275613">
			May 12, 2005 at 9:55 am</a>		</div>

		<p>People seem to be making noises about allocating and deleting the buffer on each loop iteration, without suggesting that the profiler be used to see if that&#8217;s really a bottleneck&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-275743">
				<div id="div-comment-275743" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://blogs.msdn.com/ricom/archive/2005/05/12/416977.aspx' rel='external nofollow' class='url'>Rico Mariani's Performance Tidbits</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275743">
			May 12, 2005 at 4:43 pm</a>		</div>

		<p>Stefang jumped into the fray with his analysis in the comments from my last posting.&amp;amp;nbsp; Thank you&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-275783">
				<div id="div-comment-275783" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Neil</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20050511-46/?p=35663#comment-275783">
			May 13, 2005 at 5:37 am</a>		</div>

		<p>Is the (lack of) performance of std::wifstream a fault of the library or a fault of the standard?</p>

		
				</div>
		</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>

</body>
</html>
<br/><div class="disclaimer">
*DISCLAIMER: I DO NOT OWN THIS CONTENT. If you are the owner and would like it removed, please
<a target="_blank" href="/contact.htm">contact me</a>.
The content herein is an archived reproduction of entries from
Raymond Chen's "Old New Thing" Blog (most recent link is <a target="_blank" href="https://devblogs.microsoft.com/oldnewthing/">here</a>).
It may have slight formatting modifications for consistency and to improve readability.
<br/><br/>
WHY DID I DUPLICATE THIS CONTENT HERE?
Let me first say this site has never had anything to sell and has never shown ads of any kind. I have nothing monetarily to gain by duplicating content here.
Because I had made my own local copy of this content throughout the years, for ease of using tools like grep, I decided to put it online after I discovered
some of the original content previously and publicly available, had disappeared approximately early to mid 2019.
At the same time, I present the content in an easily accessible theme-agnostic way.
<br/><br/>
The information provided by Raymond's blog is, for all practical purposes, more authoritative on Windows Development than Microsoft's
own MSDN documentation and should be considered supplemental reading to that documentation. The wealth of missing details
provided by this blog that Microsoft could not or did not document about Windows over the years is vital enough, many would agree an online "backup" of these details
is a necessary endeavor. Specifics include:<br/>
<ul>
    <li>
        A "redesign" after 2019 erased thousands of user's comments from previous years. As many have stated, the comments are nearly as important as the postings themselves.
        The archived copies of the postings contained here retain the original comments.
    </li>
    <li>
        The blog has changed domains many times and the urls have otherwise been under constant change since 2003.
        Even when proper redirection has been set up for those links, redirection only works for a limited period of time.
        For example, all of the internal blog links that were valid in early 2019, were broken by 2020 without proper redirection.
    </li>
    <li>
        The blog has been under constant re-design and re-theming since its inception.
        It is downright irritating to deal with a bogged-down site experience as the result of the latest visual themes designed for cell-phone browsers.
        As of this writing, it is cumbersome to navigate titles with only 10 entries per page.
        While it is nice that the official site has a search feature, searching using this index (with all titles on a single page) is much quicker (CTRL-F in most browsers).
    </li>
</ul>
</div><br/>
&lt;-- Back to <a href="index.htm">Old New Thing Archive Index</a>

