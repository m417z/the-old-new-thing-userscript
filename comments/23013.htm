<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (40)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment even thread-even depth-1" id="comment-612273">
				<div id="div-comment-612273" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">waleri</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612273">
			March 25, 2008 at 11:18 am</a>		</div>

		<p>If only more suitable names were chosen&#8230; like BYTE/WORD/DWORD, altghough strictly speaking they are also incorrect (since word size is CPU dependant). Best choice would be INT32 or UINT16&#8230; And we wouldn&#8217;t end up with DWORD_PTR&#8230;</p>
<p>Now where is that time machine?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612283">
				<div id="div-comment-612283" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Mark Steward</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612283">
			March 25, 2008 at 11:24 am</a>		</div>

		<p>WORD, DWORD, etc are used for the unsigned variants.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612313">
				<div id="div-comment-612313" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">SvenGroot</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612313">
			March 25, 2008 at 11:56 am</a>		</div>

		<p>Yeah, it&#8217;s eternally confusing that a WORD is actually only half a CPU word on Win32, and DWORD is a full single word. And the whole _PTR range of types is very useful, but also completely non-semantic when it comes to type naming.</p>
<p>But unfortunately science hasn&#8217;t made any progress on that time machine yet, so what can you do?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612353">
				<div id="div-comment-612353" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Aaargh!</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612353">
			March 25, 2008 at 12:17 pm</a>		</div>

		<p>&quot;Now where is that time machine?&quot;</p>
<p>It&#8217;s in the dock, second icon from the right.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612373">
				<div id="div-comment-612373" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">JM</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612373">
			March 25, 2008 at 12:37 pm</a>		</div>

		<p>It&#8217;s very common for people who don&#8217;t understand the issues at hand to blame this on the bone-headed C committee, or on the narrow-minded Microsoft developers, or on the stupid application programmers, or&#8230;</p>
<p>The paradoxical situation is that C attempts to maximize portability by not tying the integral types down to specific sizes, and programmers are just as quick to abandon that completely and weave the assumption than an int is exactly X bits into the heart of their programs, since C makes it so easy to write code that assumes these things &#8212; even though it&#8217;s almost never harder to write equivalent code that doesn&#8217;t.</p>
<p>If you think about it, though, the &quot;maximally portable&quot; approach breaks down rather easily, for exact reasons of ABI and API compatibility. What type should you use for file lengths? int? long? unsigned long? unsigned long long? Which one&#8217;s going to be big enough, you think? If your API uses a LARGE_INTEGER struct, how many people are going to want to write glue code for maintaining portability?</p>
<p>All these API-specific typedefs do have the big drawback that these types seep into perfectly portable code that doesn&#8217;t need to be tied to the Win32 API. Windows programmers are often incapable or unwilling of writing a single line of code that doesn&#8217;t require &quot;#include &lt;windows.h&gt;&quot; at the top, which is just a shame.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612383">
				<div id="div-comment-612383" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Daev</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612383">
			March 25, 2008 at 12:54 pm</a>		</div>

		<p>@SvenGroot</p>
<p>&quot;Word&quot; as a term for a two-byte quantity goes back a long way in the nomenclature of Intel processors, into the days of the 8080 and Z-80 (whose native data size was a byte). &nbsp;I remember writing DEFW to store a 16-bit number in TRS-80 Assembler.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612393">
				<div id="div-comment-612393" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Daev</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612393">
			March 25, 2008 at 12:54 pm</a>		</div>

		<p>@SvenGroot</p>
<p>&quot;Word&quot; as a term for a two-byte quantity goes back a long way in the nomenclature of Intel processors, into the days of the 8080 and Z-80 (whose native data size was a byte). &nbsp;I remember writing DEFW to store a 16-bit number in TRS-80 Assembler.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612403">
				<div id="div-comment-612403" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Yuhong Bao</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612403">
			March 25, 2008 at 12:55 pm</a>		</div>

		<p>&quot;Windows programmers are often incapable or unwilling of writing a single line of code that doesn&#8217;t require &quot;#include &lt;windows.h&gt;&quot; at the top, which is just a shame.&quot;</p>
<p>The developer of VirtualDub says that there were several bugs in MFC resulting from, say, #define GetCurrentTime() GetTickCount(). I mean, basically what is happening here is that IFoo::GetCurrentTime() become IFoo::GetTickCount(), which was hidden because MFC code usually #include &lt;windows.h&gt;.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612433">
				<div id="div-comment-612433" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Nathan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612433">
			March 25, 2008 at 1:29 pm</a>		</div>

		<blockquote><p>
  In the intervening years, most if not all compilers which target Windows have aligned their native types with Windows&#8217; platform types.
</p></blockquote>
<p>Not to be a nitpicker, but assuming this has gotten more than one programmer in trouble on 64-bit platforms. For this very reason, at the company I work for we use the C99-standardized integer types int8_t, int16_t, int32_t, and int64_t (along with their unsigned brethren) (we have the advantage of not exposing a public C API, so we can make changes like these when necessary&#8211;I fully understand that the Windows API functions were written well before the stdint types came along and thus these types are not a universal panacea).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612443">
				<div id="div-comment-612443" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Grant</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612443">
			March 25, 2008 at 1:34 pm</a>		</div>

		<p>Now that PowerPC is dead this is also probably academic, but I always figured you could assume the endian-ness of a LONG correctly vs a long if you&#8217;re (for example) trying to parse a .bmp on a Mac.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612473">
				<div id="div-comment-612473" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">guess</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612473">
			March 25, 2008 at 1:52 pm</a>		</div>

		<p>My guess would be that there was no technical reason and the uppercase typedefs were introduced in order to keep the style consistent (all type names are uppercase).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612503">
				<div id="div-comment-612503" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Cooney</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612503">
			March 25, 2008 at 2:18 pm</a>		</div>

		<blockquote><p>
  The paradoxical situation is that C attempts to maximize portability by not tying the integral types down to specific sizes, and programmers are just as quick to abandon that completely and weave the assumption than an int is exactly X bits into the heart of their programs, since C makes it so easy to write code that assumes these things &#8212; even though it&#8217;s almost never harder to write equivalent code that doesn&#8217;t.
</p></blockquote>
<p>C is portable assembler, so really, that sort of thing makes sense. It also makes guranatees on the minimum size of an int (or a long), so you can assume that a long has 32 bits you can use.</p>
<blockquote><p>
  In the intervening years, most if not all compilers which target Windows have aligned their native types with Windows&#8217; platform types.
</p></blockquote>
<p>Or rather, they&#8217;ve come to follow the unix way of doing things (more or less). Ints have been 32 bits in SPARC land for a while now.</p>
<blockquote><p>
  Now that PowerPC is dead this is also probably academic, but I always figured you could assume the endian-ness of a LONG correctly vs a long if you&#8217;re (for example) trying to parse a .bmp on a Mac.
</p></blockquote>
<p>If you want to check endianness (or just see if it differs), cash &amp;((int))1 to a char* and see of the first byte has something in it. There&#8217;s also the 0xFEFF thing that unicode uses.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612513">
				<div id="div-comment-612513" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">me</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612513">
			March 25, 2008 at 2:23 pm</a>		</div>

		<p>To waleri:</p>
<p>But: A byte is not always 8 bit. That&#8217;s the reason that network standards (e.g. from IEEE, or the RFCs from the IETF) use the name &quot;octet&quot; instead.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612573">
				<div id="div-comment-612573" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ulric</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612573">
			March 25, 2008 at 3:41 pm</a>		</div>

		<p>It has been a problem for us actually, in the places where there is inconsistent usage of LONG vs &#8216;long&#8217;.</p>
<p>We use a product called MainWin, which is an officially licensed port of Win32/Win64 to Linux. &nbsp;</p>
<p>on windows 64-bit with ms compilers:</p>
<p>int and long are 32-bit</p>
<p>64-bit linux with gcc:</p>
<p>&#8216;int&#8217; is 32-bit, LONG is 32-bit, the native compiler &#8216;long&#8217; is 64-bit .</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612633">
				<div id="div-comment-612633" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">steveg</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612633">
			March 25, 2008 at 7:20 pm</a>		</div>

		<p>I always thought Windows.h had the platform types because some genius in the Win16 days foresaw Win32 on the horizon?</p>
<p>It was MUCH easier porting to Win32 if you&#8217;d used the platform types (not that they were called that then IIRC). The porting pain was also reduced if you&#8217;d used windowsx.h &#8212; that was also a piece of genius, IMO &#8212; not just because of porting concerns, it actively encouraged people to stop writing 9000 line switch statements, and break each message into a function (here I could wax lyrical about how well MFC and OWL did[n&#8217;t] do that, but I won&#8217;t).</p>
<p>One of my favourite porting bugs i screwed up was moving an app to a new version of Irix: the OS changed PIDs from uint16 to uint32. No problems until the PID reached 2^16&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612643">
				<div id="div-comment-612643" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">edgar</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612643">
			March 25, 2008 at 7:36 pm</a>		</div>

		<p>No one remember the fight between Pascal and C ?</p>
<p>Better you wrote your one types, because you don&#8217;t know what in future happens. :)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612663">
				<div id="div-comment-612663" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">marius</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612663">
			March 25, 2008 at 9:10 pm</a>		</div>

		<p>well&#8230;.</p>
<p>In VB6 byte is a byte (8 bits), boolean is an integer actually in memory so it&#8217;s better to use byte instead of boolean, &nbsp;integer is 2 bytes, long is 4 bytes&#8230; Obviously when trying to use API functions it&#8217;s a joy&#8230;</p>
<p>If you don&#8217;t care about memory usage the application runs faster if most of the variables are of long data type&#8230;</p>
<p>VB.net had to come along and say Integer is 4 bytes, Long is 8 bytes&#8230;. for amateur programmers that want to convert their vb6 programs to .net there&#8217;ll be lots of problems.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612683">
				<div id="div-comment-612683" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Anon</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612683">
			March 25, 2008 at 10:40 pm</a>		</div>

		<p>I always thought windowsx.h was the best Win16/Win32/Win64 &#8216;application framework&#8217;, despite or maybe because there isn&#8217;t really much to it. &nbsp;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612703">
				<div id="div-comment-612703" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Worf</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612703">
			March 26, 2008 at 2:00 am</a>		</div>

		<p>Do remember that C only guarantees one thing w.r.t. native types.</p>
<p>sizeof(char) &lt;= sizeof(short) &lt;= sizeof(int) &lt;= sizeof(long)</p>
<p>64 bits is a whole new ball game. You can have ints be 64bit (forcing long to be 64 bit), int and long being 32 bit (use long long for a generic 64bit type), or int be 32 bits, and long be 64 bits. Each actually is a different way of doing 64 bit computing. At least though, pointers are 64 bit.</p>
<p>As for the word/dword&#8230; it&#8217;s architecture-specific. Motorola used word to be the native register size (32 bit), and halfword to be half that (16 bit). And things get fun with bytes, words, and longs&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612723">
				<div id="div-comment-612723" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Neil</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612723">
			March 26, 2008 at 5:28 am</a>		</div>

		<p>I thought that (U)INT were, at least in 16/32 bit land, equivalent to (unsigned) int, and it was only WORD, DWORD and LONG that had a fixed length. (Strangely enough there was no signed short.) The one oddity was WPARAM which got changed from WORD to UINT.</p>
<p>As for the windowsx.h GET_ macros, they show up the places that weren&#8217;t sufficiently forward compatible (which at least goes to show that the rest of Windows was, I guess).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612733">
				<div id="div-comment-612733" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ian</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612733">
			March 26, 2008 at 6:18 am</a>		</div>

		<p>To Grant,</p>
<p>I think you made a couple of wrong assumptions. First, the platform types are nothing to do with endianness. LONG will be big-endian on a big-endian machine and little-endian on a little-endian machine. How can a simple typedef possibly reverse byte-ordering?</p>
<p>Second, if you want to write portable code you should still take care not to assume endianness. Even if PowerPC were dead (which it isn&#8217;t) there are still plenty of other big-endian architectures.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-612753">
				<div id="div-comment-612753" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">SuperKoko</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612753">
			March 26, 2008 at 6:46 am</a>		</div>

		<p>@waleri: That would be for a specific generation of the Windows API where the ABI is perfectly defined.</p>
<p>Take a time machine, look at the Windows 16 bits -&gt; Win32 transition, and understand why INT isn&#8217;t called INT32&#8230;</p>
<p>Basically, INT is implicitly supposed to be an efficient platform-specific integer type.</p>
<p>INT: 16 bits on Windows 16 bits, 32 bits on Win32, 32 bits on Win64.</p>
<p>Yep, 32 bits integers tend to be more efficient, even on 64 bits computers, because they use far less cache and RAM.</p>
<p>LONG being 32 bits on Win64 rather than 64 bits is only for backwards compatibility with badly programmed applications assuming LONG==INT==32 bits.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613053">
				<div id="div-comment-613053" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Grant</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613053">
			March 26, 2008 at 1:25 pm</a>		</div>

		<p>My point was, if you see something like this:</p>
<p>struct IconDirectoryEntry {</p>
<p>&nbsp; &nbsp;BYTE &nbsp;bWidth;</p>
<p>&nbsp; &nbsp;BYTE &nbsp;bHeight;</p>
<p>&nbsp; &nbsp;BYTE &nbsp;bColorCount;</p>
<p>&nbsp; &nbsp;BYTE &nbsp;bReserved;</p>
<p>&nbsp; &nbsp;WORD &nbsp;wPlanes;</p>
<p>&nbsp; &nbsp;WORD &nbsp;wBitCount;</p>
<p>&nbsp; &nbsp;DWORD dwBytesInRes;</p>
<p>&nbsp; &nbsp;DWORD dwImageOffset;</p>
<p>};</p>
<p>You have a pretty good idea that things are little endian when you&#8217;re reading it from disk. &nbsp;The same wouldn&#8217;t automatically hold true if it was all chars, ints, and longs.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613093">
				<div id="div-comment-613093" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Khan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613093">
			March 26, 2008 at 1:52 pm</a>		</div>

		<p>@Worf: C guarantees more. It guarantees short and int are at least 16 bits and long is at least 32 bits.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613103">
				<div id="div-comment-613103" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Cooney</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613103">
			March 26, 2008 at 2:40 pm</a>		</div>

		<blockquote><p>
  &nbsp;The same wouldn&#8217;t automatically hold true if it was all chars, ints, and longs.
</p></blockquote>
<p>If you also write 0xFEFF to disk in a known location, you can assume that if it comes back as 0xFFFE, you need to byteswap. Goofy byte orders like 1324 seem to be a vax thing only.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613113">
				<div id="div-comment-613113" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">manyirons</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613113">
			March 26, 2008 at 2:56 pm</a>		</div>

		<p>Way back I somehow learned that short and long were like a dozen. &nbsp;A dozen is always 12, short is always 16 bits, and long is always 32 bits no matter what. &nbsp;int and word are free to change, depending on the compiler.</p>
<p>In my experience porting back and forth between various &quot;16-bit&quot; and &quot;32-bit&quot; platforms, the above was always correct.</p>
<p>I&#8217;m surprised now to hear from Ulric that &quot;long&quot; has been defined as 64 bits on Linux 64 bit gcc. &nbsp;Seems like a mistake; can&#8217;t we ever depend on anything in this business?</p>
<p>&nbsp;&#8211; Owen &#8211;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613123">
				<div id="div-comment-613123" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">manyirons</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613123">
			March 26, 2008 at 2:56 pm</a>		</div>

		<p>Way back I somehow learned that short and long were like a dozen. &nbsp;A dozen is always 12, short is always 16 bits, and long is always 32 bits no matter what. &nbsp;int and word are free to change, depending on the compiler.</p>
<p>In my experience porting back and forth between various &quot;16-bit&quot; and &quot;32-bit&quot; platforms, the above was always correct.</p>
<p>I&#8217;m surprised now to hear from Ulric that &quot;long&quot; has been defined as 64 bits on Linux 64 bit gcc. &nbsp;Seems like a mistake; can&#8217;t we ever depend on anything in this business?</p>
<p>&nbsp;&#8211; Owen &#8211;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613133">
				<div id="div-comment-613133" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">BryanK</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613133">
			March 26, 2008 at 3:11 pm</a>		</div>

		<p>manyirons: You learned it wrong. &nbsp;The only guarantee from the C language is that long is &quot;at least 32 bits&quot;, and is also &quot;at least as long as int&quot;. &nbsp;(In turn, int is &quot;at least as long as short&quot;, and short is &quot;at least 16 bits&quot;. &nbsp;Neither short nor long are &quot;exactly N bits&quot;, for any N.)</p>
<p>long can be any width that satisfies those two requirements; 16 bits for short, 32 bits for int, and 64 bits for long certainly do satisfy them.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613153">
				<div id="div-comment-613153" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">BryanK</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613153">
			March 26, 2008 at 3:16 pm</a>		</div>

		<p>Actually, now that I think about it, sizes in C might be defined in terms of a multiplier on the size of a char, not a fixed number of bits. &nbsp;A char is always one (machine) byte, and AFAIK C can compile for processors whose bytes are a size other than 8 bits. &nbsp;So the &quot;at least 16 bits&quot; requirement on shorts might in reality be &quot;at least double the number of bits in a char&quot;, and longs might be &quot;at least four times the number of bits in a char&quot;. &nbsp;Of course int is still defined as &gt;= short, &lt;= long, so that one doesn&#8217;t depend on the exact bit count.</p>
<p>But I don&#8217;t know the C definitions for sure, though I don&#8217;t see any reason to exclude 9-bit-byte CPUs. &nbsp;What I do know is that what I wrote above is valid on 8-bit-byte machines.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613213">
				<div id="div-comment-613213" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">SuperKoko</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613213">
			March 26, 2008 at 5:15 pm</a>		</div>

		<p>&quot;</p>
<p>A char is always one (machine) byte, and AFAIK C can compile for processors whose bytes are a size other than 8 bits.</p>
<p>&quot;</p>
<p>Yes. CHAR_BIT &gt;= 8</p>
<p>&quot;</p>
<p>So the &quot;at least 16 bits&quot; requirement on shorts might in reality be &quot;at least double the number of bits in a char&quot;</p>
<p>&quot;</p>
<p>Wrong. The standard requirements are about the ranges [-32767,+32767] for short and int and [-2147483647,+2147483647] for long which implies that the number of bits is &gt;= 16. Note that a binary representation, with or without padding bits, is required by the standard.</p>
<p>However, a 32 bits byte C compiler may have sizeof(char)==sizeof(short)==sizeof(int)==sizeof(long)==1. This can be seen on pure 32 bits architectures where individual bytes cannot be addressed without heavy bit mask operations.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-612933">
				<div id="div-comment-612933" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">poochner</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-612933">
			March 26, 2008 at 11:06 am</a>		</div>

		<p>Quite right, me (if that *is* your real name! :-) &nbsp;A byte can be anything from 5 to 9 bits. &nbsp;At least those are the ones I can think of. &nbsp;This is one reason async chips can handle those sizes. &nbsp;Though 9 wasn&#8217;t common on the chips for general 8-bit architectures (8080/Z80/6502, etc), since it was more of a mini-computer thing.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613233">
				<div id="div-comment-613233" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ulric</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613233">
			March 26, 2008 at 6:49 pm</a>		</div>

		<blockquote><p>
  manyirons: You learned it wrong.
</p></blockquote>
<p>yep, &#8216;long&#8217; was 64-bit on many 64-bit compilers. &nbsp;</p>
<p>To some of us, it&#8217;s Microsoft that made the mistake here, to accommodate some source-compatility that didn&#8217;t really save anyone work porting and verifying the code to win64.</p>
<p>At best, it&#8217;s a 50/50 decision.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613343">
				<div id="div-comment-613343" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">SuperKoko</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613343">
			March 27, 2008 at 9:50 am</a>		</div>

		<p>@Ulric: I admit that I, too, depreciate very much the LLP64 model.</p>
<p>Portable C90 programs makes an effective use of the computer in the LP64 model, while the LLP64 model limits C90 programs to 4GiB files, assuming they use the standard fopen API, 4GiB memory blocks, assuming the compiler is conforming to the standard C90, C++98 and C++03 specifications stating that size_t -&gt; unsigned long conversions aren&#8217;t lossy.</p>
<p>However, source-level portability of badly programmed Win32 applications (i.e. most of them) to Win64 is probably more important, at least from a marketing point of view, than standards conformance and effectiveness for portable programs.</p>
<p>From what I see, Microsoft has always got the policy: Make the transition smooth for most people, developers or users, rather than make the transition smooth &amp; effective for people who got it right (which might be a minority).</p>
<p>Making applications work rather than making them effective, is another Microsoft principle.</p>
<p>Most people and developers don&#8217;t care too much if their application is a bit slow or if it cannot open files larger than 4GiB. However, they want their applications to work!</p>
<p>Another Microsoft principle: Keeping compatibility with itself gets a higher pripority than getting compatibility with the rest of the world.</p>
<p>You may disagree with these policies, but I think they&#8217;re the root of Microsoft&#8217;s success.</p>
<p>Personally, I&#8217;m sad that Microsoft did/had-to use this ugly model.</p>
<p>LONG didn&#8217;t change from 16 bits MS-DOS to 64 bits Windows! That&#8217;s incredible.</p>
<p>BTW, don&#8217;t think that source-level compatibility isn&#8217;t important because there&#8217;s binary compatibility. Many librairies have to be rewritten and maintained for Win64. Many active projects tries to move to Win64 too, because having an heterogenous 32/64 bits development environment isn&#8217;t easy to manage.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613383">
				<div id="div-comment-613383" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">BOO</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613383">
			March 27, 2008 at 11:10 am</a>		</div>

		<p>BOOL (32-bits) differs from bool (8-bit).</p>
<p>Therefore lowercase types cannot be used interchangeably with uppercase types.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613393">
				<div id="div-comment-613393" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">size matters</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613393">
			March 27, 2008 at 11:13 am</a>		</div>

		<p>Is unfortunate C (ansi/iso c and ansi/iso c++) doesn&#8217;t have explicit sized integers.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613553">
				<div id="div-comment-613553" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Cooney</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613553">
			March 27, 2008 at 2:22 pm</a>		</div>

		<p>why is that? It needs to deal with various diverse architectures fairly closely. As I said, it&#8217;s portable assembler.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613703">
				<div id="div-comment-613703" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">size matters</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613703">
			March 28, 2008 at 9:10 am</a>		</div>

		<p>A source code becomes more portable if it can assume a fixed size of integer types.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613713">
				<div id="div-comment-613713" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">BryanK</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613713">
			March 28, 2008 at 9:26 am</a>		</div>

		<p>&quot;size matters&quot;: It does. &nbsp;See C99&#8217;s &lt;stdint.h&gt; and int32_t / uint32_t types (and friends for other sizes).</p>
<p>Oh, you&#8217;re not using a compiler that conforms to C99 (or at least this part of it)? &nbsp;Sorry to hear that&#8230;</p>
<p>:-P</p>
<p>SuperKoko: Thanks! &nbsp;The &quot;must hold at least this range of integers, and must be a binary representation&quot; definition for the various short/int/long types makes sense; I had no idea it was written that way, but that explains why people have always said &quot;at least N bits&quot;. &nbsp;:-)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-613923">
				<div id="div-comment-613923" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">dave</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613923">
			March 28, 2008 at 2:40 pm</a>		</div>

		<blockquote><p>
  A source code becomes more portable if</p>
<p>  it can assume a fixed size of integer types.
</p></blockquote>
<p>On the contrary &#8211; source code becomes less portable if it is unnecessarily tied to a particular size.</p>
<p>Let us assume you want to operate on numbers that are in the range 0 to 9999. &nbsp; You choose to type the data as &quot;exactly 16 bit integer&quot;. Your hardware has 16-bit integer ops, so that&#8217;s ok.</p>
<p>Now you want your program to run on hardware that doesn&#8217;t have 16-bit integer ops; if the data is forced to 16-bit size, then the code has to contort itself. &nbsp;</p>
<p>And you probably didn&#8217;t even care, really.</p>
<p>Much better to use (in C) &quot;int&quot; or &quot;unsigned int&quot;, which is a natural integer size for the machine.</p>
<p>Apart from cases where you need to match externally-defined reality, you should use sizes that are large enough but not overly specified.</p>
<p>These days, C says that an int is at least 16 bits and a long is at least 32 bits, but I prefer to code as if an int is at least 32 bits (thus avoiding needless use of long types, just in case logn turns out to mean 128 bits). &nbsp;I am quite confident my code will never need to run on a 16-bit-int machine.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-613953">
				<div id="div-comment-613953" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">SuperKoko</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20080325-00/?p=23013#comment-613953">
			March 28, 2008 at 3:57 pm</a>		</div>

		<p>@size matters:</p>
<p>&quot;</p>
<p>Is unfortunate C (ansi/iso c and ansi/iso c++) doesn&#8217;t have explicit sized integers.</p>
<p>&quot;</p>
<p>Aren&#8217;t you aware of the 9 years old standard C release?</p>
<p>C99 DOES have explicitly sized integers.</p>
<p>@dave:</p>
<p>For good portability of programs *and* file formats, you need both machine-specific integers and specified integers.</p>
<p>&quot;</p>
<p>Much better to use (in C) &quot;int&quot; or &quot;unsigned int&quot;, which is a natural integer size for the machine.</p>
<p>&quot;</p>
<p>Until you wish to write this into a file, and exchange the file.</p>
<p>&quot;I am quite confident my code will never need to run on a 16-bit-int machine.&quot;</p>
<p>And you argue that your practice is portable!</p>
<p>I&#8217;d rather use int_fast32_t.</p>

		
				</div>
		</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>