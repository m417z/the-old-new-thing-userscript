<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (31)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment even thread-even depth-1 parent" id="comment-1267685">
				<div id="div-comment-1267685" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Roman</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267685">
			October 7, 2016 at 11:48 am</a>		</div>

		<p>If you select a Unicode-only locale, how do the ANSI functions (*A) work?</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-archangelpip odd alt depth-2" id="comment-1267695">
				<div id="div-comment-1267695" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Darran+Rowe' rel='external nofollow' class='url'>Darran Rowe</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267695">
			October 7, 2016 at 2:07 pm</a>		</div>

		<p>They most likely don&#8217;t work consistently.<br />
There are some functions that are implemented by calling WideCharToMultiByte, converting it to a Unicode string, and this will probably fail because of the lack of the ANSI codepage.<br />
So in general, if you are using a Unicode only codepage, use the W functions.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 parent" id="comment-1267686">
				<div id="div-comment-1267686" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Myria</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267686">
			October 7, 2016 at 1:10 pm</a>		</div>

		<p>If only Windows allowed you to set CP_UTF8 as the default code page&#8230;  *sigh*</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-archangelpip odd alt depth-2 parent" id="comment-1267705">
				<div id="div-comment-1267705" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Darran+Rowe' rel='external nofollow' class='url'>Darran Rowe</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267705">
			October 7, 2016 at 2:09 pm</a>		</div>

		<p>Of course, there is one other way to look at this.<br />
If only Linux didn&#8217;t choose the awful hack to keep using codepages when they had the chance to make Unicode output independent of the codepage. All of this was just to be lazy and allow them to keep using what they knew&#8230; *sigh*</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-3 parent" id="comment-1267735">
				<div id="div-comment-1267735" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267735">
			October 7, 2016 at 5:46 pm</a>		</div>

		<p>That&#8217;s nothing to do with it and you know it. Setting your locale to UTF-8 is *how* you detach it from a code page. </p>
<p>GP wants to do this on Windows so he can use UTF-8 on the myadrids of non UTF-8 programs, most of which will work if given half a chance.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-archangelpip odd alt depth-4" id="comment-1267745">
				<div id="div-comment-1267745" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Darran+Rowe' rel='external nofollow' class='url'>Darran Rowe</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267745">
			October 7, 2016 at 6:12 pm</a>		</div>

		<p>Well, tbh, it this was basically a counter moan to a rather stupid moan.<br />
The choice that Windows took a long time ago to do what it did to output Unicode can be viewed as just as stupid as the choices that Linux took to get it to work.<br />
But no, setting your locale to UTF-8 is not how you detach from a code page. First, a locale has a lot more in it than just the code page for the character set it uses, the formatting for dates/times and other stuff is in there. Secondly, just because you set your locales code page to UTF-8, doesn&#8217;t mean you are detached from code page output. By definition you are still using a code page.<br />
The real problem here is the programming languages. For C, it only really has functions for char and wchar_t, and because of how undefined wchar_t is, then it is hard to use portably. So as a crutch, UTF-8 was used a lot throughout the language as a code page and pretended that it wasn&#8217;t a code page.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even depth-2 parent" id="comment-1267715">
				<div id="div-comment-1267715" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Dan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267715">
			October 7, 2016 at 3:59 pm</a>		</div>

		<p>Microsoft had the luxury of writing a new operating system (Windows NT) from scratch, which introduced the opportunity for a shiny new API using wide characters.  The UTF-8 locale “codepage” approach (as used in the *nix world) has the advantage of backwards-compatibility.</p>
<p>Using UTF-16 for the OS API wasn&#8217;t IMO *inherently* a poor decision, but it interacts poorly with the C++ standard library that basically treats wchar_t as an afterthought.  For example, there is no wide-character version of std::exception::what.  Nor a wide-character equivalent of fopen (_wfopen is a Microsoft-specific extension) or even main (_wmain, again, is Microsoft-specific).</p>
<p>In the 7-bit ASCII days, you could write a cross-platform library by sticking to “Standard” C or C++ as much as possible and falling back to low-level OS-specific functions (wrapped in #ifdef) only when doing something that wasn&#8217;t standardized (like walking a directory tree, spawning a thread, or making a GUI).</p>
<p>But on Windows, all Standard C++ functions that take a char* are “defective” in that they can&#8217;t represent the entire character repertoire supported by the underlying OS for filenames or console output.  So to support Unicode properly, you have to actively *avoid* the standard library and use the Windows-specific _w functions.</p>
<p>This makes it a royal PITA to write code that is simultaneously Unicode-aware and cross-platform.  I&#8217;ve had to do this.  The approach I&#8217;ve taken is to use UTF-8 everywhere as the standard character encoding, and write wrapper functions that do a behind-the-scenes UTF-8 to UTF-16 conversion on Windows, like so:</p>
<p>FILE* fopen_utf8(const char* path, const char* mode)<br />
{<br />
#ifdef _WIN32<br />
   FILE* hFile = NULL;<br />
   _wfopen_s(&amp;pstFile, ToWstring(path).c_str(), ToWstring(mode).c_str());<br />
   return pstFile;<br />
#else<br />
   return fopen(path, mode);<br />
#endif<br />
}</p>
<p>&#8230;and repeat as necessary for stat, getenv, etc.</p>
<p>If Windows supported CP_UTF8 as the ANSI code page, I could just use good old fopen.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-archangelpip odd alt depth-3 parent" id="comment-1267755">
				<div id="div-comment-1267755" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Darran+Rowe' rel='external nofollow' class='url'>Darran Rowe</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267755">
			October 7, 2016 at 6:34 pm</a>		</div>

		<p>I would say you are slightly wrong with this.<br />
The thing to remember is that to use the new Unicode related stuff, these applications would have to be rebuilt for 32 bit Windows anyway. The functions in the Windows headers are protected by macros to choose which versions of the functions you wanted, choosing ANSI by default.<br />
So just by running the 16 bit application you would get ANSI behaviour, if you recompiled it and fixed the 16 bit &#8211; 32 bit problems, then you would still get ANSI behaviour if you didn&#8217;t give the compiler the Unicode macro options.<br />
Also, remember that Microsoft were early adopters to the Unicode standard, and they got bit by this. You say &#8220;Using UTF-16 for the OS API wasn’t IMO *inherently* a poor decision,&#8221; but back when they adopted it, there wasn&#8217;t a UTF-16, there was only UCS-4 and UCS-2. UTF-8 wasn&#8217;t fully specified until 1992-1993, and Windows NT and the Win32 API was developed 2 years prior to that.<br />
But one thought here is that the problem isn&#8217;t the choices of the O/S&#8217; involved, but the choices of the programming languages. C still isn&#8217;t fixing the functions that are lacking and there is no good standard library to work with I/O in Unicode. C++ has tried to fix some of these, but it is still lacking, and the last time I checked, iostreams still couldn&#8217;t output char16_t or char32_t based strings.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-yuhong-bao even depth-4 parent" id="comment-1267826">
				<div id="div-comment-1267826" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Yuhong+Bao' rel='external nofollow' class='url'>Yuhong Bao</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267826">
			October 9, 2016 at 11:01 am</a>		</div>

		<p>I have been thinking for example to warn developers that a MBCS may exceed two bytes with NT 3.1, then actually implement UTF-8 as ACP/OEMCP with NT 3.5.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-oldnewthing bypostauthor odd alt depth-5" id="comment-1267845">
				<div id="div-comment-1267845" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267845">
			October 9, 2016 at 12:30 pm</a>		</div>

		<p>And then everybody will says &#8220;Don&#8217;t upgrade to NT 3.5. It screws up strings in pretty much all apps.&#8221;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even depth-5" id="comment-1267855">
				<div id="div-comment-1267855" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267855">
			October 9, 2016 at 1:40 pm</a>		</div>

		<p>@Raymond: That&#8217;s not what would have happened. What would have happened is &#8220;Don&#8217;t use UTF-8 code page; it breaks programs.&#8221; And a decade from then those programs would have faded into obscurity.</p>
<p>The obvious trick here is to implement the darn thing but *don&#8217;t* make it the default. You don&#8217;t want it to be the default anyway because it messes with how you interpret text files. And then when AppLocale came along (it was rather obvious it would come along) it would more or less clean up the problem.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-yuhong-bao odd alt depth-5" id="comment-1267865">
				<div id="div-comment-1267865" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Yuhong+Bao' rel='external nofollow' class='url'>Yuhong Bao</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267865">
			October 9, 2016 at 1:53 pm</a>		</div>

		<p>Yea, I agree that it should not be the default. Also NT 3.1 and 3.5 would have been so early that there would not have been many Win32 programs in the first place.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor even depth-5" id="comment-1267875">
				<div id="div-comment-1267875" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267875">
			October 9, 2016 at 2:39 pm</a>		</div>

		<p>Would you have delayed the release of Windows NT 3.5 to fix all the in-box apps so they could support UTF-8 as the ANSI code page?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-yuhong-bao odd alt depth-5" id="comment-1267895">
				<div id="div-comment-1267895" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Yuhong+Bao' rel='external nofollow' class='url'>Yuhong Bao</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267895">
			October 9, 2016 at 3:01 pm</a>		</div>

		<p>See Chris Walker&#8217;s comment in <a href="http://archives.miloush.net/michkap/archive/2005/01/20/357028.html" rel="nofollow">http://archives.miloush.net/michkap/archive/2005/01/20/357028.html</a></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-archangelpip even depth-5" id="comment-1267925">
				<div id="div-comment-1267925" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Darran+Rowe' rel='external nofollow' class='url'>Darran Rowe</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267925">
			October 10, 2016 at 12:43 am</a>		</div>

		<p>The big problem is, UTF-8 didn&#8217;t really take off until the explosion in the use of the internet around 2000 or so. Until that time, it was anyone&#8217;s guess as to what way things would go. What&#8217;s more, when did Linux actually start using UTF-8 as an output character set? The earliest articles I can find date it back to 2000 or 2001, so there is also the expectation here that Windows should have somehow seen 7 years into the future and made a decision about an encoding that didn&#8217;t even exist when the Win32 API was designed.<br />
But anyway, instead of complaining like this about past decisions, maybe all of you should put effort into standardising a library and proposing to either the C or C++ standards committee for adoption? In the end this is the only way to get proper standards defined behaviour without relying on implementation defined behaviour.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt depth-5" id="comment-1268025">
				<div id="div-comment-1268025" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268025">
			October 10, 2016 at 4:03 pm</a>		</div>

		<p>@Raymond Chen: In fact only two, but this might be with the benefit of hindsight. Notepad would need to be fixed (and we *know* this one is trivial) and the console would need to be fixed (we now know this one as conhost.exe but it was once part of csrss.exe).</p>
<p>If you managed to guess AppLocale would exist the rest can be derived but it&#8217;s far less obvious if you didn&#8217;t manage it. I might well have held for conhost because of the fact the bugs are reachable now and were reachable then.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor even depth-5" id="comment-1268035">
				<div id="div-comment-1268035" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268035">
			October 10, 2016 at 4:18 pm</a>		</div>

		<p>Plus File Manager (because if File Manager required AppLocale, that would suck), and the common file dialogs (because that runs in-process, and the host process might not have AppLocale enabled), and the window manager and the standard controls and the common controls, and GDI too. And then of course people would say &#8220;Why bother adding support for UTF-8 as CP_ACP if you can&#8217;t even finish the job?&#8221;</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt depth-5" id="comment-1268055">
				<div id="div-comment-1268055" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268055">
			October 10, 2016 at 5:20 pm</a>		</div>

		<p>All the A-&gt;W functions would just work. On the other hand for file manager if it&#8217;s not converted to UTF-8 locale support, it&#8217;s broken if it doesn&#8217;t call all W functions. If it calls all W functions it needs no conversions. Same for OpenFileName/SaveFileName. AFAIK This leaves only the edit control. (Everybody else could be an A-&gt;W function). The W edit control didn&#8217;t work until Vista.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-samuel-bronson even depth-4 parent" id="comment-1269095">
				<div id="div-comment-1269095" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Samuel+Bronson' rel='external nofollow' class='url'>Samuel Bronson</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1269095">
			October 15, 2016 at 2:44 pm</a>		</div>

		<p>Yeah, UTF-16 not exist when NT was created, and in fact <a href="http://www.unicode.org/faq/utf_bom.html" rel="nofollow">Unicode was specified as a having a 16-bit code space until July 1996</a>, so the choice to use a 16-bit representation for WCHAR really wasn&#8217;t that unreasonable given the information available at the time.</p>
<p><b>Note:</b> If, like me, you find yourself extremely confused as to why the Unicode consortium would bother to specify a 32-bit interchange format for a 16-bit code, you&#8217;ll be relieved to hear that this did not in fact happen.  In fact, UCS-2 and UCS-4 come from<a href="https://en.wikipedia.org/wiki/Universal_Coded_Character_Set#History" rel="nofollow">ISO 10646</a>, which originally specified a 31-bit code space, for which a 32-bit interchange format is the glaringly obvious approach.  ISO 10646 divided this 31-bit code space into 128 groups of 256 planes of 256 rows of 256 cells. Originally, UCS-2 was intended to be used along with <a href="https://en.wikipedia.org/wiki/ISO_2022" rel="nofollow">ISO 2022</a> escape characters to represent characters beyond the Basic Multilingual Plane; to make this work, it would have been necessary to ban octets in the C0 and C1 control ranges (0x00-0x1F and 0x80-0x9F, respectively).  If you&#8217;re not horrified yet, consider that ISO 2022 is <b>stateful</b>, that <a href="http://www.unicode.org/Public/reconstructed/1.0.0/UnicodeData.txt" rel="nofollow">Unicode 1.0 used many such codepoints</a> (anything from 0100 to 01FF, for starters, plus something like a quarter of the rest), and so this concept for ISO 10646 would have left us with <b>two</b> character encoding standards to rule them all, if adopted. (And still using ISO 2022 for code-switching.)</p>
<p>Fortunately for all of us, the computer industry talked enough national bodies into voting against that version of ISO 10646, so the ISO 10646 standardizers ended up dropping the whole ISO 2022 thing, including the prohibitions on using C0/C1 bytes as components, and then negotiating a unification with Unicode. (But this was all too late to really affect NT&#8217;s API: Unicode 1.1 (the first unified version) didn&#8217;t ship until June 1993, and NT 3.1 shipped on July 27, 1993.)</p>
<p>Unfortunately, it turned out that a 16-bit code space was not enough, so now we have UTF-16 and (I assume) a lot of software that doesn&#8217;t support it properly, because for most european languages the BMP is quite enough (aside from the occasionally emoji, which will only rarely trigger anything but the simplest bugs) :-(.</p>

		
				</div>
		<ol class="children">
		<li class="comment odd alt depth-5" id="comment-1270456">
				<div id="div-comment-1270456" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Dan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1270456">
			October 19, 2016 at 4:29 pm</a>		</div>

		<p>The original 31-bit ISO 10646 proposal is also why UTF-8 was originally designed with support for 4-, 5-, and 6-byte code sequences.  (BMP characters only require the 1-, 2-, or 3-byte sequences).</p>
<p>This came in handy when the Unicode Consortium decided that 65 536 characters weren&#8217;t enough for everyone after all.  Frameworks using 16-bit characters to represent Unicode strings had to introduce the variable-length UTF-16 “surrogate” mechanism in order to be able to use the new characters.  UTF-8-based software merely needed to dust off a subset of the 4-byte sequences (representing U+10000 through U+10FFFF) that had originally been intended for ISO 10646.</p>
<p>Exercise for the reader: Suppose that Unicode decides to add so many emoji or obscure historical logographic scripts that the existing 17-plane code space becomes too confining.  Design an encoding for representing the extra characters in 16-bit string APIs that&#8217;s as backwards-compatible as possible with UTF-16.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even depth-3" id="comment-1268005">
				<div id="div-comment-1268005" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Myria</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268005">
			October 10, 2016 at 12:34 pm</a>		</div>

		<p>One little problem: UTF-8 was published about 6 months before Windows NT 3.1 came out.  UTF-8 didn&#8217;t exist when the OS was designed and most of it was being written.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor odd alt depth-2 parent" id="comment-1267725">
				<div id="div-comment-1267725" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267725">
			October 7, 2016 at 4:37 pm</a>		</div>

		<p>The problem is that a lot of apps assume that MaxCharSize for CP_ACP is never more than 2.</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-3 parent" id="comment-1267817">
				<div id="div-comment-1267817" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">osexpert</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267817">
			October 8, 2016 at 4:17 pm</a>		</div>

		<p>Won&#8217;t MaxCharSize be 1 for UTF8? Isnt the whole point that UTF8 is indistinguishable from ANSI?</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-archangelpip odd alt depth-4 parent" id="comment-1267825">
				<div id="div-comment-1267825" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Darran+Rowe' rel='external nofollow' class='url'>Darran Rowe</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267825">
			October 8, 2016 at 6:42 pm</a>		</div>

		<p>The point of UTF-8 is to make a byte oriented Unicode encoding, it has nothing to do with making it indistinguishable from ANSI.<br />
Unicode itself has combining characters, so a single character can be made up of two or mode code points. UTF-8 is an encoding of Unicode, so it has to be able to support everything that Unicode itself supports, this means that UTF-8 has to allow variable length characters.</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-5" id="comment-1267885">
				<div id="div-comment-1267885" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">osexpert</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267885">
			October 9, 2016 at 2:55 pm</a>		</div>

		<p>Unicode says it is compatible with ASCII so I don&#8217;t see MaxCharSize = 1 as completely wrong. If code can handle ASCII it can handle UTF8, thou it would be wrong in case it uses own logic for strlen etc. but should be ok if it uses OS functions and OS knows how to handle UTF8 (this is the missing part). I think it would work fine in most cases, but would probably have to be an opt-in\own risk. No guts no glory:-)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt depth-5" id="comment-1268315">
				<div id="div-comment-1268315" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Dan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268315">
			October 11, 2016 at 3:34 pm</a>		</div>

		<p>@osexpert: How do you define the “length” of a string?  As the number of user-perceived graphemes (which may differ, for the same sequence of code points, between different languages)?  As the number of Unicode code points?  Or as the number of bytes the string takes up in memory?  The last of these is quite useful in practical situations, like allocating a buffer in which to store a string, and it works just fine with UTF-8.</p>
<p>The difficulty with ASCII-centric code is functions like toupper/tolower that work on individual char values, which obviously don&#8217;t cope with multi-byte characters.</p>
<p>But, *if* a program or library is compatible with “any locale-specific character encoding that&#8217;s a superset of ASCII” (I&#8217;m excluding here font rendering engines or similar components whose raison d&#8217;être is low-level text manipulation, that care very deeply about which specific encoding a string is in), and does *not* have any hard-coded assumptions that 2-byte, 3-byte, or 4-byte characters can&#8217;t exist, it can cope perfectly well with UTF-8.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-oldnewthing bypostauthor even depth-4 parent" id="comment-1267835">
				<div id="div-comment-1267835" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267835">
			October 9, 2016 at 12:29 pm</a>		</div>

		<p>When the user hits the left or right arrow key, or hits Backspace or Delete, the program needs to decide how much to move / how many bytes to delete. Old programs do this by checking whether a byte is a DBCS lead byte. If so, then it and the next byte are considered one unit. Otherwise, just the byte itself is the unit. This completely falls apart not just for UTF-8 but for Unicode in general, because Unicode grapheme clusters can span multiple code points. if you report MaxCharSize=1, then the cursor is going to be in the middle of a UTF-8 sequence, and then hitting backspace will do, um, interesting things.</p>

		
				</div>
		<ol class="children">
		<li class="comment odd alt depth-5" id="comment-1267935">
				<div id="div-comment-1267935" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">French Guy</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267935">
			October 10, 2016 at 6:49 am</a>		</div>

		<p>It&#8217;s quite simple to delete a full code point in UTF-8, since it&#8217;s easy to tell whether a given byte is leading (non-leading ones are of the form 10xxxxxx). You keep deleting until you hit the leading byte (and delete it). To delete a full character, you do more of the same. When deleting a code point, you check its general category. If it&#8217;s a combining mark (general category Mc, Me or Mn), you continue deleting (until you delete a code point that is not a combining mark).</p>
<p>However, the maximum length in bytes is quite high given the sheer number of combining characters in Unicode (and if you&#8217;re not limited to distinct combining characters, there&#8217;s no maximum length at all).</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even depth-4" id="comment-1268285">
				<div id="div-comment-1268285" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Dan</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268285">
			October 11, 2016 at 3:02 pm</a>		</div>

		<p>For UTF-8, MaxCharSize = 4.  This actually works if you call GetCPInfo with CP_UTF8 as the first parameter.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-samuel-bronson odd alt thread-even depth-1 parent" id="comment-1268465">
				<div id="div-comment-1268465" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Samuel+Bronson' rel='external nofollow' class='url'>Samuel Bronson</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268465">
			October 12, 2016 at 11:56 am</a>		</div>

		<p>This probably explains why the Unix world could (eventually, mostly?) get away with switching to UTF-8 for the locale-default encoding: relatively few programs were visual to start with, and I really don&#8217;t think very many of those were keen on implementing their own text entry widgets from scratch, so this kind of cursor-motion craziness probably didn&#8217;t crop up so much.</p>
<p>Also, at least on GNU/Linux, it was/is <i>comparatively</i> simple to change encodings: rather than being a purchase-time choice, system-wide setting, or per-user setting as on Windows, the locale is determined by environment variables, and working around a GUI program&#8217;s inability to handle UTF-8 could be as simple as setting something like <code>LANG=en_US</code> in its environment (assuming you still had that locale listed in <code>/etc/locale.gen</code> (compared to the <code>LANG=en_US.UTF-8</code> that the program couldn&#8217;t handle).</p>
<p>I think Unix programs have also had to deal with somewhat more horrific encodings than Windows has ever seen fit to use, too, so that a mere up-to-4-bytes-per-codepoint encoding like UTF-8 is like child&#8217;s play by comparison.  I certainly don&#8217;t remember any isdbcslead() function to give anyone the impression that it was safe to assume that no more than two bytes in a row would be needed to represent a character&#8230;</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-samuel-bronson even depth-2" id="comment-1268475">
				<div id="div-comment-1268475" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Samuel+Bronson' rel='external nofollow' class='url'>Samuel Bronson</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1268475">
			October 12, 2016 at 11:59 am</a>		</div>

		<p>Oops, this was meant to be a reply to Raymond&#8217;s <a href="https://blogs.msdn.microsoft.com/oldnewthing/20161007-00/?p=94475#comment-1267835">When the user hits the left or right arrow key, or hits Backspace or Delete &#8230;</a> comment; I guess I lost the relevant query parameter when I logged into my account :-(.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>