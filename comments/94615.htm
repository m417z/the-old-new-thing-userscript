<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (38)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment even thread-even depth-1 parent" id="comment-1271615">
				<div id="div-comment-1271615" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://www.delta-n.nl/' rel='external nofollow' class='url'>Arnaud van Galen</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271615">
			November 1, 2016 at 7:35 am</a>		</div>

		<p>&#8220;We live in a post-file-system-compression world&#8221;<br />
For home use: Definitively, but for Servers (IIS/SharePoint-logfiles) and versions/editions of SQL Server that cannot compress backups file-system-compression can save a whole lot of expensive diskspace</p>

		
				</div>
		<ol class="children">
		<li class="comment odd alt depth-2" id="comment-1272215">
				<div id="div-comment-1272215" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">MarcK4096</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272215">
			November 4, 2016 at 6:51 am</a>		</div>

		<p>For servers, you can use Windows deduplication.  And some time in the future, ReFS block cloning will allow deduplication to be implemented without any of the rehydration penalties.  NTFS file compression should go away.  I tried it years ago on a Windows Server 2003 file server and it created a huge amount of fragmentation that decimated performance.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 parent" id="comment-1271635">
				<div id="div-comment-1271635" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">DWalker07</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271635">
			November 1, 2016 at 7:56 am</a>		</div>

		<p>Right; compressing a JPG or an XLSX or a DOCX file will give a same-sized or slightly smaller file, but not by much.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-kai-schatzl odd alt depth-2" id="comment-1271705">
				<div id="div-comment-1271705" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Kai+Sch%C3%A4tzl' rel='external nofollow' class='url'>Kai Schätzl</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271705">
			November 1, 2016 at 9:04 am</a>		</div>

		<p>It even may actually yield a slightly bigger file.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even depth-2" id="comment-1271845">
				<div id="div-comment-1271845" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Tom</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271845">
			November 1, 2016 at 12:44 pm</a>		</div>

		<p>The docx is a zipfile anyway&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1" id="comment-1271656">
				<div id="div-comment-1271656" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Antonio Rodríguez</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271656">
			November 1, 2016 at 8:24 am</a>		</div>

		<p>Another scenario where file compression helps is when you have an slow hard drive or SSD. In that case, file compression can actually give you a better throughput. In mi case, I still have three (not one, not two, but three) Acer Aspire One 110 in working condition. You know, the ones that came with a slow SSD. I use the SSD just for the OS and the software, and put all the data in the second card reader (intended for storage expansion). That way, I can have the SSDs compressed so they are faster (even with the low-power Atom 260) and have more capacity. The storage cards, on the other hand, are uncompressed: they are formatted in FAT32, and most of their space is used by music, videos and compressed archives, so I wouldn&#8217;t gain much.</p>
<p>But in the days of 500 MB/s transfer speeds, even the speed benefit of file compression is void.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-mike-dimmick even thread-odd thread-alt depth-1" id="comment-1271675">
				<div id="div-comment-1271675" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Mike+Dimmick' rel='external nofollow' class='url'>Mike Dimmick</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271675">
			November 1, 2016 at 8:42 am</a>		</div>

		<p>You can&#8217;t fit any new storage into WIMBoot devices, however. My girlfriend&#8217;s laptop has 32GB of non-expandable internal storage &#8211; 7GB of which was lost to the boot/recovery partition. Upgrading to Windows 10 basically made this redundant but there was no way to recover the space. When it came to installing the Windows 10 Anniversary Update, it failed due to insufficient space, but there was genuinely nothing on there apart from Windows itself. I had to do a wipe and clean install to perform the update.</p>
<p>Windows was already reporting that it was in the compressed state, but forcing compression did gain some extra. A little. Not enough to actually install the OS update!</p>
<p>In sum &#8211; the compression algorithm is still important.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent" id="comment-1271685">
				<div id="div-comment-1271685" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Tramb</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271685">
			November 1, 2016 at 8:48 am</a>		</div>

		<p>It would be better if MS made NTFS better and allowed *customers* to decide in which world they want to live.<br />
Many people (me included) seem to think ZFS (or btrfs) have useful features (I shan&#8217;t list these, you know what they are)</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-andycadley2 even depth-2 parent" id="comment-1271695">
				<div id="div-comment-1271695" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/AndyCadley' rel='external nofollow' class='url'>AndyCadley</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271695">
			November 1, 2016 at 8:57 am</a>		</div>

		<p>Windows has supported installable file systems for some time now. If you want to use ZFS or Btrfs, you&#8217;re welcome to write one</p>

		
				</div>
		<ol class="children">
		<li class="comment odd alt depth-3" id="comment-1271725">
				<div id="div-comment-1271725" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271725">
			November 1, 2016 at 9:08 am</a>		</div>

		<p>And how do you boot Windows from one?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even depth-3 parent" id="comment-1271815">
				<div id="div-comment-1271815" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Tramb</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271815">
			November 1, 2016 at 11:20 am</a>		</div>

		<p>The point is that I understand that NTFS doesn&#8217;t have every feature in the world but don&#8217;t try to convince me I don&#8217;t need them.</p>
<p>&#8220;If you want to use ZFS or Btrfs, you’re welcome to write one&#8221;<br />
I can accept &#8220;You can contribute&#8221; messages for OSes I don&#8217;t pay for, not for Windows.</p>

		
				</div>
		<ol class="children">
		<li class="comment odd alt depth-4 parent" id="comment-1271855">
				<div id="div-comment-1271855" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Klimax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271855">
			November 1, 2016 at 2:18 pm</a>		</div>

		<p>The only feature I know NTFS lacks are checksums on file content. ReFS fixes that. Are there any other feature missing? And in previous post you mention &#8220;world&#8221;, you mean what compression should be used? That would be confusing, rarely used and even rarer understood. And for little benefit. Just extra testing of unused code.</p>
<p>IIRC if you want to augment it, then you can write your own driver filter or other add-on, but I don&#8217;t see rationale for general solution or mostly nonexistent problem.</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-5" id="comment-1272015">
				<div id="div-comment-1272015" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='http://nbtparse.org' rel='external nofollow' class='url'>Kevin</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272015">
			November 2, 2016 at 11:25 am</a>		</div>

		<p>ZFS and btrfs are next-generation filesystems.  If installed correctly (e.g. in a RAID configuration), they are quite capable of automagically healing file corruption, and quite a few other neat tricks like COW snapshots.  Ars Technica did a nice feature on these things a while ago: <a href="http://arstechnica.com/information-technology/2014/01/bitrot-and-atomic-cows-inside-next-gen-filesystems/" rel="nofollow">http://arstechnica.com/information-technology/2014/01/bitrot-and-atomic-cows-inside-next-gen-filesystems/</a></p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt depth-5" id="comment-1272025">
				<div id="div-comment-1272025" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Tramb</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272025">
			November 2, 2016 at 11:44 am</a>		</div>

		<p>I was specifically thinking of ubiquitous checksumming and deduplication.<br />
Is ReFs a real possibility on the modern Windows desktop right now (bootable and choosable at install) ?<br />
And compression has its use on top of user-space compression because the fs and vm can maintain caches of uncompressed blocks, avoiding redundant unpacking between processes. I was referring to &#8220;We live in a post-file-system-compression world.&#8221;. I disagreed.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even depth-5" id="comment-1272075">
				<div id="div-comment-1272075" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Klimax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272075">
			November 2, 2016 at 4:13 pm</a>		</div>

		<p>By those definitions NTFS is next gen already&#8230; And ReFS doesn&#8217;t need RAID for fixing corruption at all. COW is IIRC under dedup, which is already supported in NTFS</p>
<p>So in short, there is nothing missing in NTFS. (with sole exception of checksum and those were introduced with ReFS)<br />
Note: ReFS doesn&#8217;t appear yet bootable, but can&#8217;t confirm that.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-mngoldeneagle odd alt depth-2 parent" id="comment-1271715">
				<div id="div-comment-1271715" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/MNGoldenEagle' rel='external nofollow' class='url'>MNGoldenEagle</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271715">
			November 1, 2016 at 9:07 am</a>		</div>

		<p>That&#8217;s why they made ReFS.  Would be nice if they expanded ReFS&#8217;s feature set so it could host Windows on it, but I&#8217;m guessing they&#8217;re still waiting for it to fully stabilize and vet out before they take the next step considering the implications it&#8217;d have for customers.</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-3 parent" id="comment-1271825">
				<div id="div-comment-1271825" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Koro</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271825">
			November 1, 2016 at 11:36 am</a>		</div>

		<p>Isn&#8217;t ReFS a copy-paste of the NTFS code, tweaked by people who have no idea how the original code worked?</p>

		
				</div>
		<ol class="children">
		<li class="comment odd alt depth-4 parent" id="comment-1271865">
				<div id="div-comment-1271865" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Klimax</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271865">
			November 1, 2016 at 2:18 pm</a>		</div>

		<p>No.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-cheong even depth-5" id="comment-1271915">
				<div id="div-comment-1271915" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/cheong00' rel='external nofollow' class='url'>cheong00</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271915">
			November 2, 2016 at 2:33 am</a>		</div>

		<p>Agreed. Actually there are some features that exists on NTFS but not (yet) supported in ReFS.</p>
<p><a href="https://blogs.technet.microsoft.com/askpfeplat/2013/01/01/windows-server-2012-does-refs-replace-ntfs-when-should-i-use-it/" rel="nofollow">https://blogs.technet.microsoft.com/askpfeplat/2013/01/01/windows-server-2012-does-refs-replace-ntfs-when-should-i-use-it/</a></p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt depth-4" id="comment-1271895">
				<div id="div-comment-1271895" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">GDwarf</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271895">
			November 1, 2016 at 5:55 pm</a>		</div>

		<p>Not even remotely? It doesn&#8217;t have some features NTFS does (hard links, for one) but has several that NTFS doesn&#8217;t, and is based on a fundamentally different way of performing file operations (Copy-on-Write). You might as well call ZFS &#8220;just a FAT clone&#8221;.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1" id="comment-1271745">
				<div id="div-comment-1271745" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Florian S.</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271745">
			November 1, 2016 at 9:27 am</a>		</div>

		<p>I&#8217;ve never seen it as the file system&#8217;s job to compress files on disk, even back in the days when disk space really mattered (I think it still matters, even in the TB era. All that this much free space led to was wasteful behavior. Same goes for RAM.) That&#8217;s what compressed container formats are for, and they are system-independent, too. And you can copy them without decompressing the data first (I assume that when you copy file system compressed data from one disk to another, it needs to be decompressed on the source and recompressed on the target, doesn&#8217;t it? Or does Windows pass the compressed data directly?)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent" id="comment-1271755">
				<div id="div-comment-1271755" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Mc</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271755">
			November 1, 2016 at 9:38 am</a>		</div>

		<p>Does the compression just compress the file contents,  or the actual file system itself?<br />
  i.e.  If you have 8K clusters  and write a 4K file that gets compressed to 2K is there still 6K of wasted, unused space on the cluster that can&#8217;t be reused for other files?</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-2" id="comment-1271795">
				<div id="div-comment-1271795" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Richard Wells</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271795">
			November 1, 2016 at 10:10 am</a>		</div>

		<p>IIRC, compression will combine files into a single allocation chunk and save on slack space that way. If the combined size of all the files being compressed is less than 64kB or greater than 50GB, NTFS compression may not be the correct solution.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1 parent" id="comment-1271765">
				<div id="div-comment-1271765" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Pilchard123</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271765">
			November 1, 2016 at 9:45 am</a>		</div>

		<p>I think you might have made a typo in your second paragraph. You refer to values M and N that you are not privy to, by use &#8216;M%&#8217; twice and never (presumably) &#8216;N%&#8217;. An interesting post, nonetheless.</p>
<p>Nit-pickery, ho!</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-2" id="comment-1271775">
				<div id="div-comment-1271775" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Pilchard123</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271775">
			November 1, 2016 at 9:47 am</a>		</div>

		<p>And, of course, I have typo&#8217;d myself; &#8216;by use&#8217; should be &#8216;but use&#8217;. Muphry&#8217;s law strikes again&#8230;</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1" id="comment-1271785">
				<div id="div-comment-1271785" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Roger</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271785">
			November 1, 2016 at 9:50 am</a>		</div>

		<p>The Windows 10 installer and anniversary update installer both refuse to install if the &#8220;drive&#8221; is compressed.  I couldn&#8217;t quite work out what it is looking at, and I think it only examined the top level directories and tree of \WINDOWS.  It sure was annoying having to decompress to install, and then recompress afterwards.</p>
<p>So why do I have compression?  On a laptop because it is shared with Linux and I wanted Windows as small as possible.  On a desktop because it is running off a 2TB spinning drive, and a blazingly fast processor so the less I/O the better.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-scott-brickey even thread-odd thread-alt depth-1" id="comment-1271796">
				<div id="div-comment-1271796" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Scott+Brickey' rel='external nofollow' class='url'>Scott Brickey</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271796">
			November 1, 2016 at 10:12 am</a>		</div>

		<p>My main question for these types of requirements, is how they might be unit tested. I say this because unit testing for performance requirements (but also for comparing the performance among several implementations) has been annoying for me, historically &#8211; partially due to the ability to take measurements, but also because of newer technologies like SpeedStepping.</p>
<p>At the time, I suspect that all the CPUs ran at full speed (fixed clock speed)&#8230; so a simple timer and eyeball for CPU use was probably sufficient&#8230; but I&#8217;d love to hear how the testing would be performed in today&#8217;s landscape.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1" id="comment-1271805">
				<div id="div-comment-1271805" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">John Vert</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271805">
			November 1, 2016 at 10:30 am</a>		</div>

		<p>Maybe true, but the Alpha AXP decompression was twice as fast as all the other architectures because it could decompress 64-bits at a time. The other architectures (at the time) were limited to 32-bit chunks.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1" id="comment-1271835">
				<div id="div-comment-1271835" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Mihkel Soomere</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271835">
			November 1, 2016 at 12:40 pm</a>		</div>

		<p>Actually NTFS compression is still very useful, for example on small SSDs where any saved space is a big win.<br />
Windows 10 seems to have added some new compression algorithms (LZX, XPRESS4K etc)  in compact.exe however there isn&#8217;t much documentation on these.<br />
Anything interesting to tell us about these new algorithms?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment byuser comment-author-alegrigoriev odd alt thread-even depth-1" id="comment-1271846">
				<div id="div-comment-1271846" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/alegr1' rel='external nofollow' class='url'>alegr1</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271846">
			November 1, 2016 at 1:26 pm</a>		</div>

		<p>Step 1: Make LINK write the PDB into compressed files.<br />
Step 2: Be surprised that now PDB write takes a lot of time compared with the rest of LINK.<br />
Step 3: Find some interns to separate PDB write to a separate thread.<br />
Step 4 ?<br />
Step 5: Nothing really changed. Your giant Windows build will still take as much time.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1" id="comment-1271885">
				<div id="div-comment-1271885" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ted M</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271885">
			November 1, 2016 at 3:11 pm</a>		</div>

		<p>I forgot I had full write access to the entirety of the system drive in a Windows Vista install (it was during my &#8220;more admin access is better&#8221; idiot phase) and I managed to (what I assume was) compress the boot loader. That took a while to fix.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1" id="comment-1271925">
				<div id="div-comment-1271925" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Bruce Hoult</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271925">
			November 2, 2016 at 3:55 am</a>		</div>

		<p>I find this very hard to believe. The Alpha had all the normal boolean operations (if not more) and arbitrary arithmetic or logical shifts by literal or dynamic counts. It even had population count and count leading zeroes.</p>
<p>As far as I&#8217;m aware, these were all fast operations, even on the 21064, not bit by bit or something. The manual even says to do bitfield extraction by a left shift followed by a right shift (to make all unwanted bits fall off the end), and sign extension by a left shift to align the value to the left of the register followed by an arithmetic right shift to replicate the sign bit. I don&#8217;t think they&#8217;d tell you do do this if it was slow. </p>
<p>The first Alpha didn&#8217;t have BYTE loads and stores, only full word, but that doesn&#8217;t hamper compression (or other) algorithms when you have fast shifting and masking. Well, and competent programmers, of course. And that certainly would not somehow favour nibble-sized data over arbitrary bit sizes.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1 parent" id="comment-1271985">
				<div id="div-comment-1271985" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Stephen Donaghy</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1271985">
			November 2, 2016 at 9:16 am</a>		</div>

		<p>I&#8217;m surprised nobody in the comments thus far has mentioned data deduplication yet. I think a lot of the &#8220;Reasons why I still use compression&#8221; are solved largely by switching data dedup on. Of course it&#8217;s only really available in windows server, which is a shame.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-alegrigoriev odd alt depth-2 parent" id="comment-1272035">
				<div id="div-comment-1272035" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/alegr1' rel='external nofollow' class='url'>alegr1</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272035">
			November 2, 2016 at 12:15 pm</a>		</div>

		<p>Data deduplication only helps if you have a lot of files with identical blocks, for example, a lot of VM virtual disks with Windows images on it. In general client usage scenarios it just doesn&#8217;t happen.</p>

		
				</div>
		<ol class="children">
		<li class="comment even depth-3" id="comment-1272105">
				<div id="div-comment-1272105" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">smf</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272105">
			November 3, 2016 at 5:01 am</a>		</div>

		<p>Data deduplication gives you free &#8220;sparse files&#8221; without the application having to be coded specially.</p>
<p>There are other scenarios than working with multiple VM&#8217;s.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt depth-3" id="comment-1272225">
				<div id="div-comment-1272225" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">MarcK4096</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272225">
			November 4, 2016 at 6:53 am</a>		</div>

		<p>Windows deduplication does do compression.  IMO, there&#8217;s no reason to choose NTFS file compression over it.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment byuser comment-author-martin-baschnegger even thread-even depth-1" id="comment-1272065">
				<div id="div-comment-1272065" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Martin+Ba.+_' rel='external nofollow' class='url'>Martin Ba. _</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272065">
			November 2, 2016 at 1:32 pm</a>		</div>

		<p>&#8220;We live in a post-file-system-compression world.&#8221; &#8211; Others already mentioned it, but at this moment I think we are very much *not*:<br />
Small form factor devices (the mention 32GB tablet) and still limited SSD sizes, combined with a bazillion locations that do *not* store compressed data (Looking at you, C:\Windows\Installer &#8211; 10GB vs. 8GB compressed &#8211; a 2GB save is a 2GB save on a few hunnerd GB SSD)</p>
<p>So, the article was nice, but &#8220;We live in a post-file-system-compression world.&#8221; is just not true. It&#8217;s still useful.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1272115">
				<div id="div-comment-1272115" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">smf</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20161101-00/?p=94615#comment-1272115">
			November 3, 2016 at 5:05 am</a>		</div>

		<p>&#8220;The compression algorithm must be system-independent. In other words, you cannot change the compression algorithm depending on what machine you are running on. Well, okay, you can compress differently depending on the system, but every system has to be able to decompress every compression algorithm.&#8221;</p>
<p>I disagree. Ideally the algorithm and parameters would be selectable by the user, if the user wants to select the option that makes it degrade so that the disk can be shared with an Alpha AXP then it&#8217;s up to them. The ultimate situation would be that users could install their own compression engines. If you mount a disk on a system without that particular engine then you&#8217;d get a suitable error when you try to access the files (although again ideally you&#8217;d still be able to access the compressed version of the files).</p>

		
				</div>
		</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>