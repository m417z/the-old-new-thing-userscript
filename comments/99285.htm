<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (5)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment even thread-even depth-1 parent" id="comment-1352755">
				<div id="div-comment-1352755" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">JAS</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20180719-00/?p=99285#comment-1352755">
			July 19, 2018 at 4:10 pm</a>		</div>

		<p>When the CPU freeing the blocks experiences a glut, how does this get resolved?  I can only imagine some kind of global lock-less queue where you post all blocks over N, and where the empty CPUs will go if they run out.</p>

		
				</div>
		<ol class="children">
		<li class="comment odd alt depth-2" id="comment-1352805">
				<div id="div-comment-1352805" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Jon</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20180719-00/?p=99285#comment-1352805">
			July 20, 2018 at 3:34 am</a>		</div>

		<p>The global queue doesn&#8217;t need to be lockless.  Since you&#8217;re not going to be using the global queue often, and since you&#8217;re less likely to have multiple CPUs accessing it at the same time, performance doesn&#8217;t matter so much.  You can have rules like:</p>
<p>* On free, if there are 2N blocks in the CPU-local queue, take a global lock and move N blocks from the CPU-local queue to the global queue, leaving N blocks in the CPU-local queue.</p>
<p>* When you want to allocate a block, if the CPU-local queue is empty, take a lock, take one block from the global queue, and also move N blocks from the global queue to the CPU-local queue (or until the global queue is empty, if it had less than N blocks in it).  If the global queue was empty, allocate 2N+1 blocks using malloc() and put N of them in the CPU-local queue, N of them in the global queue, and return 1.</p>
<p>With this design, each CPU will only access the global queue when there have been N more allocations than frees, or N more frees than allocations.  The maximum amount of memory used is (peak_actual_usage + 2*N*number_of_cpus) blocks (or less).</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		<li class="comment even thread-odd thread-alt depth-1" id="comment-1352815">
				<div id="div-comment-1352815" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20180719-00/?p=99285#comment-1352815">
			July 20, 2018 at 6:54 am</a>		</div>

		<p>I vaguely recall seeing a heapfree-like function that could free a block on to the wrong heap somehow. I shudder to think what heapdestroy would do to that.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-even depth-1 parent" id="comment-1354015">
				<div id="div-comment-1354015" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Dennis</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20180719-00/?p=99285#comment-1354015">
			July 27, 2018 at 6:40 pm</a>		</div>

		<p>I&#8217;m not sure if I buy this argument. It seems like using the processor id will reduce contention on allocation and won&#8217;t do *worse* than random assignment for free. (I can&#8217;t think of a way to assign threads to heaps guaranteed to do better than random.)  If the workload does a lot more allocating than freeing, (perhaps it allocates incrementally and frees it all in the end) then processor id might pull ahead. (It might end up allocating memory from many heaps, though.)</p>
<p>There are problems using the processor id if the processes are loaded funny, or if the CPUs are asymmetric. On the other hand, maybe using the processor id helps in the NUMA case.</p>
<p>Using per CPU lists is obviously better since you can go lock-free, but if you are going to take a lock, using the processor id isn&#8217;t *that* bad.</p>

		
				</div>
		<ol class="children">
		<li class="comment byuser comment-author-oldnewthing bypostauthor even depth-2" id="comment-1354025">
				<div id="div-comment-1354025" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn"><a href='https://social.msdn.microsoft.com/profile/Raymond+Chen+-+MSFT' rel='external nofollow' class='url'>Raymond Chen - MSFT</a></cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20180719-00/?p=99285#comment-1354025">
			July 27, 2018 at 9:20 pm</a>		</div>

		<p>You can assign a heap to each thread. Then there is no contention because the thread will free the memory back to its dedicated heap.</p>

		
				</div>
		</li><!-- #comment-## -->
</ol><!-- .children -->
</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>