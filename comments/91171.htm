<table class="commenttable" cellspacing="0" cellpadding="0"><tr><td><div class="commentdiv"><div class="commentdivhdr">
<!-- COMMENTS START -->
Comments (14)	</div>

	
			<div class="navigation pagination clear-both">
					</div>

		<ol class="comment-list">
					<li class="comment even thread-even depth-1" id="comment-1196711">
				<div id="div-comment-1196711" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">henke37</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196711">
			August 5, 2015 at 7:36 am</a>		</div>

		<p>All these complicated dependency trickery makes me happy not to be writing a compiler for this processor.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1196701">
				<div id="div-comment-1196701" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Scott Brickey</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196701">
			August 5, 2015 at 8:23 am</a>		</div>

		<p>&gt; If profiling suggests [&#8230;] can use speculation</p>
<p>since profiling occurs during compilation, I assume this only applies when the code contains mixed uses of the aliased pointers&#8230; I would assume that if profiling identifies no such pointers, other optimizations would be made instead (negating the need for speculation and advanced loading, while still maintaining the wider/shorter dependency chain)?</p>
<p>Also, given the amount of additional effort/complexity when compiling on IA64, how much extra work/time is spent by the compiler as compared to x86?</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1196691">
				<div id="div-comment-1196691" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ben Voigt</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196691">
			August 5, 2015 at 8:42 am</a>		</div>

		<p>@henke37: Yet, the x86 family tries to do a lot of this (speculative read, speculative execution, recovery) *in hardware*. &nbsp;I guess the micro-ops decoder is more or less a x86-&gt;IA64 recompiler. &nbsp;Just consider how much more complicated that is to debug (and how much more difficult to issue a patch!) and how wasteful of power because the dataflow analysis has to rerun on each execution.</p>
<p>Doing it in the compiler is definitely a more efficient approach. &nbsp;The downside is that the binary now is specific to a particular implementation architecture (to distinguish from Instruction Set Architecture). &nbsp;While x86 just-in-time speculation decisions are specific to the CPU generation &#8212; the same code can transparently take advantage of newer processors. &nbsp;The benefits of ahead-of-time scheduling depend on the expected ratio of executions to hardware upgrades&#8230;. for server workloads that ratio is astronomical and the ahead-of-time approach pays dividends.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1196681">
				<div id="div-comment-1196681" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Gabe</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196681">
			August 5, 2015 at 9:30 am</a>		</div>

		<p>Ben Voigt: Doing it in the compiler may be more efficient for an ahead-of-time compiler, but what about a just-in-time compiler? When your web server compiles a whole web site the first time it is accessed, you want that compilation to be as fast as possible.</p>
<p>Plus, you really want to have your instruction stream take as few bytes as possible so that you spend your time executing instructions rather than waiting to fetch them. If you think of the x86 instruction set as a compression scheme, it makes a lot of sense.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1196671">
				<div id="div-comment-1196671" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Zack</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196671">
			August 5, 2015 at 10:11 am</a>		</div>

		<p>There&#39;s another reason OOO hardware beats ahead-of-time scheduling: it has *more information* available to it. &nbsp;Specifically, it has adaptive branch prediction and accurate information about memory access latency.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1196661">
				<div id="div-comment-1196661" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Joshua</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196661">
			August 5, 2015 at 11:45 am</a>		</div>

		<p>@henke37: Yeah, especially given RyuJIT&#39;s problems. I&#39;d be darn pissed off facing that in the system compiler.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1196641">
				<div id="div-comment-1196641" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Gabe</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196641">
			August 5, 2015 at 1:20 pm</a>		</div>

		<p>Zack: Yes, it&#39;s amazing what you can do if you have 100,000,000 extra transistors in your budget!</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1196631">
				<div id="div-comment-1196631" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ben Voigt</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196631">
			August 5, 2015 at 1:45 pm</a>		</div>

		<p>@Zack: Ahead of time scheduling doesn&#39;t exclude adaptive branch prediction. &nbsp;In fact, ahead-of-time scheduling leaves more of your transistor budget for leveraging runtime information.</p>
<p>@Gabe: Just-in-time compilation is great for web development, but horrible for production scales (for the same reasons).</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1196621">
				<div id="div-comment-1196621" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Brian</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196621">
			August 5, 2015 at 2:01 pm</a>		</div>

		<p>@Scott Brickey</p>
<p>The profiler can stick hints into the code that the compiler can consume (for example, saying which branch should be considered the primary branch to optimize). &nbsp;I&#39;ve use this tooling once, but forgot what it&#39;s called. &nbsp;Basically, you write the code, compile it, run it through the profiler with several &quot;typical cases&quot;, and then use the profiler output to instrument the code. &nbsp;Once the instrumentation is complete, you recompile and let the optimizer do its magic.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1196611">
				<div id="div-comment-1196611" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Malcolm</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196611">
			August 5, 2015 at 2:59 pm</a>		</div>

		<p>Now I begin to see why the Itanium took so long to deliver!</p>
<p>It is an incredibly complex architecture, but I begin to see what its advantages are. I guess the development effort wasn&#39;t wasted, as modern processors use a lot of the same optimising logic internally, while appearing to be x86/x64 processors on the outside&#8230; although yes, admittedly, doing it at compilation time is more efficient.</p>
<p>Raymond, I look forward to the proposed overview of the Alpha, if you choose to do it. I spent many years looking after Alpha NT and VMS systems (and also a NetApp cluster &#8211; they used to use Alpha chips). Alpha was another great chip architecture which stagnated and then eventually died out, but its technology lives on in modern products :)</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1196601">
				<div id="div-comment-1196601" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Alex</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196601">
			August 5, 2015 at 9:02 pm</a>		</div>

		<p>reversed?</p>
<p>m_errno at offset 4, and m_readCount at offset 8.</p>
<p>vs</p>
<p>addl &nbsp; &nbsp;r30 = 08h, r32 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;// calculate &amp;m_errno</p>
<p>addl &nbsp; &nbsp;r29 = 04h, r32 ;; &nbsp; &nbsp; &nbsp; // calculate &amp;m_readCount</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1196581">
				<div id="div-comment-1196581" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Scott Brickey</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196581">
			August 6, 2015 at 8:33 am</a>		</div>

		<p>@Brian,</p>
<p>so &quot;profiler&quot; doesn&#39;t *just* mean code analysis, it can also mean &quot;average use case&quot; (in the case of optimizing the ASM for IA64). Cool :) Thx for response.</p>
<p>Raymond: a brief look at the tools, as it relates to stuff like this, would be another great article topic (probably after completing the ASM aspects).. also, as mentioned, a brief performance comparison of the build tools/times: how much time is spent on the more complex ASM features, in profile optimizations, etc.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment even thread-even depth-1" id="comment-1196571">
				<div id="div-comment-1196571" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Ben Voigt</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196571">
			August 6, 2015 at 8:59 am</a>		</div>

		<p>@Brian: You&#39;re probably thinking of the term &quot;Profile Guided Optimization&quot;. &nbsp;Interestingly enough, some of the hot path optimizations (which are the focus of PGO, but not exclusive to it) can actually affect correctness in weird ways. &nbsp;The basic idea is for basic blocks in the hot path to be placed consecutively in as few code pages as possible (maximizing effectiveness of instruction cache) while infrequently executed code (usually error recovery) is moved out of the working set. &nbsp;The result is that error handling is likely to incur page faults in addition to the original fault, and if the cache manager encounters an I/O error while trying to map the page containing the slow path&#8230;. well, your failure may escalate in ways that a less optimized binary wouldn&#39;t.</p>

		
				</div>
		</li><!-- #comment-## -->
		<li class="comment odd alt thread-odd thread-alt depth-1" id="comment-1196531">
				<div id="div-comment-1196531" class="comment-body">
				<div class="comment-author vcard">
						<cite class="fn">Yukkuri</cite> <span class="says">says:</span>		</div>
		
		<div class="comment-meta commentmetadata"><a href="https://blogs.msdn.microsoft.com/oldnewthing/20150805-00/?p=91171#comment-1196531">
			August 6, 2015 at 12:45 pm</a>		</div>

		<p>That is silly. You don&#39;t optimize your software for the &#39;the backing store for my pagefile is dying&#39; case. If that is happening the system has a foot in the grave already.</p>

		
				</div>
		</li><!-- #comment-## -->
		</ol><!-- .comment-list -->

		<div class="navigation pagination">
					</div>

	
			<p class="no-comments">Comments are closed.</p>
<!-- COMMENTS END -->
</div></td></tr></table>